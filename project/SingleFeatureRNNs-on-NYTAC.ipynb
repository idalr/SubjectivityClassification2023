{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e0f36fa",
   "metadata": {},
   "source": [
    "***Description***\n",
    "<div> This notebook displays the training of different single-feature model for the main task (subjectivity classification).\n",
    "<div> In the first part, I listed all the libraries, customized functions, helper functions, etc.\n",
    "<div>Then, I imported data, namely, the training data ('train_finance' - or NYTAC data on the topic of finance in the years 1996 and 2005), and testing data ('test' - or NYTAC data on 6 different topics (including 'finance') in the first three months of the year 1986). This would shade lights on whether each feature could help the model generalize cross-genres and over time.\n",
    "<div> The features trained on are: 3 argumentation feautures (ArgFeat3, originally designed by Alhindi et al. 2020), 6 argumentation features (ArgFeat6), ternary sentence-level sentiment (Sent-sum), compound sentence-level sentiment (Sent-com), sentence-level POS counts (POS-count), sentence-level POS sequences as padded array (POS-pad), and article-level POS sequence (POS-seq)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "983d9fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/users/rldall/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package tagsets to\n",
      "[nltk_data]     /home/users/rldall/nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# All packages\n",
    "from ast import literal_eval\n",
    "from collections import Counter\n",
    "import glob, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "# keras\n",
    "import keras\n",
    "from keras import Input, Model\n",
    "from keras import backend as K\n",
    "from keras.constraints import maxnorm\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional, Concatenate, Embedding, Dense, Dropout, InputLayer, Reshape, SimpleRNN, GRU, BatchNormalization, TimeDistributed, Lambda, Activation, MaxPooling1D\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import np_utils\n",
    "# NLTK\n",
    "import nltk\n",
    "from nltk.data import load\n",
    "from nltk import word_tokenize\n",
    "from nltk import StanfordTagger\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('tagsets')\n",
    "tagdict = load('help/tagsets/upenn_tagset.pickle')\n",
    "# torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import transformers\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3aa1cf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set val_set\n",
    "val_ratio = 0.2\n",
    "seed = 32\n",
    "maxlen = 100\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "321bc04a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize POS label encoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(list(tagdict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92ead474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customized keras metrics\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd08ad1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for POS tagging task\n",
    "PAD_VALUE = 99\n",
    "MAX_SENT_PAD = 50\n",
    "MAX_SENTS = 100\n",
    "MAX_POS_PAD = 2000\n",
    "\n",
    "# POS padding\n",
    "def pad_sent(sent):\n",
    "    sent_le = le.transform(sent)\n",
    "    if len(sent_le) > MAX_SENT_PAD:\n",
    "        sent_le = sent_le[:MAX_SENT_PAD]\n",
    "    sent_pos_padded = np.pad(np.array(sent_le), (0, MAX_SENT_PAD-len(sent_le)) , 'constant', constant_values=(PAD_VALUE))\n",
    "    return sent_pos_padded\n",
    "\n",
    "def pad_article(article):\n",
    "    art_pos_pad = np.empty(shape=(MAX_SENTS, MAX_SENT_PAD))\n",
    "    art_pos_pad.fill(PAD_VALUE)\n",
    "    for i,sent in enumerate(article):\n",
    "        if i < MAX_SENTS:\n",
    "            try:\n",
    "                art_pos_pad[i] = pad_sent(sent,MAX_SENT_PAD)   \n",
    "            except:\n",
    "                pass\n",
    "    return art_pos_pad\n",
    "\n",
    "# POS count\n",
    "def counter_pos(article):\n",
    "    a =[]  \n",
    "    for idx,sent_pos in enumerate(article):\n",
    "        count_pos = Counter(sent_pos)\n",
    "        a.append(dict(count_pos))\n",
    "    return a\n",
    "        \n",
    "def pos_count_article(counter_result, pos_index):\n",
    "    article_pos_count_array = np.zeros(shape=(maxlen,len(le.classes_)))\n",
    "    for art_i,sent_pos_count in enumerate(counter_result):\n",
    "        if art_i >= maxlen:        \n",
    "            pass\n",
    "        else:\n",
    "            for pos_item in sent_pos_count:\n",
    "                try:\n",
    "                    item_idx = pos_index.index(pos_item)\n",
    "                    article_pos_count_array[art_i,item_idx] = sent_pos_count.get(pos_item)\n",
    "                except:\n",
    "                    pass\n",
    "    return article_pos_count_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb42388",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bf2c784",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_files(path, startwith):\n",
    "    list_of_files = []\n",
    "    files = os.listdir(path)\n",
    "    for file in files:\n",
    "        if file.startswith(startwith):\n",
    "            list_of_files.append(str(path)+str(file))\n",
    "            \n",
    "    return list_of_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd8b48c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: /data/ProcessedNYT/train_finance.txt\n"
     ]
    }
   ],
   "source": [
    "# use train_finance as the train data\n",
    "list_of_train_files = select_files('/data/ProcessedNYT/','train')\n",
    "train_df = pd.read_csv(list_of_train_files[2], sep='\\t', header=None)\n",
    "print('Training data:', list_of_train_files[2])\n",
    "\n",
    "# use 1986 data as test data\n",
    "list_of_files = select_files('/data/ProcessedNYT/','test')\n",
    "list_of_dfs = [pd.read_csv(file, sep='\\t', header=None) for file in list_of_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf4685a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: /data/ProcessedNYT/all_finance.txt\n"
     ]
    }
   ],
   "source": [
    "# use all_finance as the train data\n",
    "list_of_files = select_files('/data/ProcessedNYT/','all')\n",
    "train_df = pd.read_csv(list_of_files[2], sep='\\t', header=None)\n",
    "print('Training data:', list_of_files[2])\n",
    "\n",
    "# use all_* data as test data\n",
    "list_of_dfs = [pd.read_csv(file, sep='\\t', header=None) for file in list_of_files]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790b3650",
   "metadata": {},
   "source": [
    "# First Model: Reproduction: ArgFeat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2be67dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "2226 train sequences\n",
      "557 test sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (2226, 100)\n",
      "x_test shape: (557, 100)\n"
     ]
    }
   ],
   "source": [
    "# load and define data\n",
    "labels = train_df[0].values\n",
    "labels = pd.get_dummies(labels).to_numpy()\n",
    "X_argfeat3 = train_df[6].apply(literal_eval)\n",
    "max_features = 3\n",
    "\n",
    "print('Loading data...')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_argfeat3, labels, test_size=val_ratio, random_state=seed)\n",
    "\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)#, dtype=\"int32\", truncating=\"pre\")\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "print('x_train shape:', X_train.shape)\n",
    "print('x_test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47867e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 128)         384       \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 128)               32896     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,538\n",
      "Trainable params: 33,538\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-13 10:54:05.249429: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-13 10:54:06.118913: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10413 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:84:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "# build model\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(SimpleRNN(128, dropout=0.2)) #, recurrent_dropout=0.5\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy',f1_m])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e4a4c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 9s 108ms/step - loss: 0.4037 - accuracy: 0.8369 - f1_m: 0.8362 - val_loss: 0.2593 - val_accuracy: 0.8995 - val_f1_m: 0.9033\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 7s 105ms/step - loss: 0.3782 - accuracy: 0.8540 - f1_m: 0.8540 - val_loss: 0.3698 - val_accuracy: 0.8312 - val_f1_m: 0.8317\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 7s 104ms/step - loss: 0.3261 - accuracy: 0.8715 - f1_m: 0.8656 - val_loss: 0.2683 - val_accuracy: 0.8851 - val_f1_m: 0.8857\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 7s 102ms/step - loss: 0.2919 - accuracy: 0.8769 - f1_m: 0.8794 - val_loss: 0.2437 - val_accuracy: 0.9048 - val_f1_m: 0.9056\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 7s 102ms/step - loss: 0.2524 - accuracy: 0.9030 - f1_m: 0.9029 - val_loss: 0.2488 - val_accuracy: 0.8923 - val_f1_m: 0.8915\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.2488 - accuracy: 0.8923 - f1_m: 0.8915\n",
      "Test score: 0.24883030354976654\n",
      "Test accuracy: 0.8922800421714783\n",
      "Test f1 score: 0.8915017247200012\n"
     ]
    }
   ],
   "source": [
    "# train, validate, save\n",
    "print('Train...')\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=5,\n",
    "          validation_data=(X_test, y_test))\n",
    "\n",
    "model.save(\"ModelWeights/af3_reproduction.h5\")\n",
    "\n",
    "score, acc, f1 = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n",
    "print('Test f1 score:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4ce919e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: /data/ProcessedNYT/test_military.txt\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.1899 - accuracy: 0.9355 - f1_m: 0.9301\n",
      "Test score: 0.1898823380470276\n",
      "Test accuracy: 0.9355372190475464\n",
      "Test f1 score: 0.9301140308380127\n",
      "Evaluating: /data/ProcessedNYT/test_law.txt\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.2778 - accuracy: 0.8836 - f1_m: 0.8885\n",
      "Test score: 0.2778244912624359\n",
      "Test accuracy: 0.8836065530776978\n",
      "Test f1 score: 0.8885301351547241\n",
      "Evaluating: /data/ProcessedNYT/test_finance.txt\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.2029 - accuracy: 0.9373 - f1_m: 0.9314\n",
      "Test score: 0.20292405784130096\n",
      "Test accuracy: 0.9372549057006836\n",
      "Test f1 score: 0.9314201474189758\n",
      "Evaluating: /data/ProcessedNYT/test_education.txt\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.1970 - accuracy: 0.9426 - f1_m: 0.9453\n",
      "Test score: 0.1970166712999344\n",
      "Test accuracy: 0.9425675868988037\n",
      "Test f1 score: 0.9453365206718445\n",
      "Evaluating: /data/ProcessedNYT/test_politics.txt\n",
      "43/43 [==============================] - 1s 19ms/step - loss: 0.2401 - accuracy: 0.9090 - f1_m: 0.9076\n",
      "Test score: 0.24012404680252075\n",
      "Test accuracy: 0.9090247750282288\n",
      "Test f1 score: 0.9075931310653687\n",
      "Evaluating: /data/ProcessedNYT/test_medicine.txt\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.2881 - accuracy: 0.8680 - f1_m: 0.8718\n",
      "Test score: 0.2881244719028473\n",
      "Test accuracy: 0.867986798286438\n",
      "Test f1 score: 0.8718429803848267\n"
     ]
    }
   ],
   "source": [
    "# evaluating the model, using data from different topics/year\n",
    "for idx,df in enumerate(list_of_dfs):\n",
    "    \n",
    "    print('Evaluating:',list_of_files[idx])\n",
    "    \n",
    "    labels = df[0].values\n",
    "    labels = pd.get_dummies(labels).to_numpy()\n",
    "    X_argfeat3 = df[6].apply(literal_eval)\n",
    "    X_test = sequence.pad_sequences(X_argfeat3, maxlen=maxlen)\n",
    "    \n",
    "    score, acc, f1 = model.evaluate(X_test, labels, batch_size=batch_size)\n",
    "    print('Test score:', score)\n",
    "    print('Test accuracy:', acc)\n",
    "    print('Test f1 score:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84676584",
   "metadata": {},
   "source": [
    "# Extended Model: ArgFeat6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3710e4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "2226 train sequences\n",
      "557 test sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (2226, 100)\n",
      "x_test shape: (557, 100)\n"
     ]
    }
   ],
   "source": [
    "# load and define data\n",
    "labels = train_df[0].values\n",
    "labels = pd.get_dummies(labels).to_numpy()\n",
    "X_argfeat6 = train_df[7].apply(literal_eval)\n",
    "max_features = 6\n",
    "\n",
    "print('Loading data...')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_argfeat6, labels, test_size=val_ratio, random_state=seed) ######\n",
    "\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)#, dtype=\"int32\", truncating=\"pre\")\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "print('x_train shape:', X_train.shape)\n",
    "print('x_test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd199560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, None, 128)         768       \n",
      "                                                                 \n",
      " simple_rnn_1 (SimpleRNN)    (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,922\n",
      "Trainable params: 33,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build model\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(SimpleRNN(128, dropout=0.2)) #, recurrent_dropout=0.5\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy',f1_m])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd7ddac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 9s 107ms/step - loss: 0.4569 - accuracy: 0.8158 - f1_m: 0.8129 - val_loss: 0.3391 - val_accuracy: 0.8312 - val_f1_m: 0.8317\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 7s 105ms/step - loss: 0.2731 - accuracy: 0.8908 - f1_m: 0.8902 - val_loss: 0.2263 - val_accuracy: 0.9084 - val_f1_m: 0.9107\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 7s 104ms/step - loss: 0.2413 - accuracy: 0.9021 - f1_m: 0.9016 - val_loss: 0.2099 - val_accuracy: 0.9228 - val_f1_m: 0.9229\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 7s 104ms/step - loss: 0.2315 - accuracy: 0.9133 - f1_m: 0.9112 - val_loss: 0.2441 - val_accuracy: 0.9048 - val_f1_m: 0.9062\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 7s 104ms/step - loss: 0.2270 - accuracy: 0.9097 - f1_m: 0.9111 - val_loss: 0.2055 - val_accuracy: 0.9102 - val_f1_m: 0.9148\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.2055 - accuracy: 0.9102 - f1_m: 0.9148\n",
      "Test score: 0.2055189460515976\n",
      "Test accuracy: 0.9102333784103394\n",
      "Test f1 score: 0.9147651195526123\n"
     ]
    }
   ],
   "source": [
    "# train, validate, save\n",
    "print('Train...')\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=5,\n",
    "          validation_data=(X_test, y_test))\n",
    "\n",
    "model.save(\"ModelWeights/af6.h5\")\n",
    "\n",
    "score, acc, f1 = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n",
    "print('Test f1 score:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e15690ca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: /data/ProcessedNYT/test_military.txt\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.4558 - accuracy: 0.8992 - f1_m: 0.8993\n",
      "Test score: 0.4557538628578186\n",
      "Test accuracy: 0.8991735577583313\n",
      "Test f1 score: 0.899330735206604\n",
      "Evaluating: /data/ProcessedNYT/test_law.txt\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.9221 - accuracy: 0.7869 - f1_m: 0.7969\n",
      "Test score: 0.9221323728561401\n",
      "Test accuracy: 0.7868852615356445\n",
      "Test f1 score: 0.7968749403953552\n",
      "Evaluating: /data/ProcessedNYT/test_finance.txt\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.5490 - accuracy: 0.8745 - f1_m: 0.8742\n",
      "Test score: 0.5490012764930725\n",
      "Test accuracy: 0.8745098114013672\n",
      "Test f1 score: 0.8742187023162842\n",
      "Evaluating: /data/ProcessedNYT/test_education.txt\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.7831 - accuracy: 0.8176 - f1_m: 0.8125\n",
      "Test score: 0.7831103205680847\n",
      "Test accuracy: 0.8175675868988037\n",
      "Test f1 score: 0.8124998807907104\n",
      "Evaluating: /data/ProcessedNYT/test_politics.txt\n",
      "43/43 [==============================] - 1s 18ms/step - loss: 0.6692 - accuracy: 0.8486 - f1_m: 0.8485\n",
      "Test score: 0.6692087054252625\n",
      "Test accuracy: 0.8486171960830688\n",
      "Test f1 score: 0.8485463857650757\n",
      "Evaluating: /data/ProcessedNYT/test_medicine.txt\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7594 - accuracy: 0.8053 - f1_m: 0.8050\n",
      "Test score: 0.7594481110572815\n",
      "Test accuracy: 0.8052805066108704\n",
      "Test f1 score: 0.8049999475479126\n"
     ]
    }
   ],
   "source": [
    "# evaluating the model, using data from different topics/year\n",
    "for idx,df in enumerate(list_of_dfs):\n",
    "    \n",
    "    print('Evaluating:',list_of_files[idx])\n",
    "    \n",
    "    labels = df[0].values\n",
    "    labels = pd.get_dummies(labels).to_numpy()\n",
    "    X_argfeat6 = df[6].apply(literal_eval) \n",
    "    X_test = sequence.pad_sequences(X_argfeat6, maxlen=maxlen) \n",
    "    \n",
    "    score, acc, f1 = model.evaluate(X_test, labels, batch_size=batch_size)\n",
    "    print('Test score:', score)\n",
    "    print('Test accuracy:', acc)\n",
    "    print('Test f1 score:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555c21c1",
   "metadata": {},
   "source": [
    "# Extended Model: Sent_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f21b198f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "2520 train sequences\n",
      "631 test sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (2520, 100)\n",
      "x_test shape: (631, 100)\n"
     ]
    }
   ],
   "source": [
    "# load and define data\n",
    "X_sent_sum = train_df[4].apply(literal_eval)\n",
    "labels = train_df[0].values\n",
    "labels = pd.get_dummies(labels).to_numpy()\n",
    "max_features = 3\n",
    "\n",
    "print('Loading data...')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sent_sum, labels, test_size=val_ratio, random_state=seed)\n",
    "\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)#, dtype=\"int32\", truncating=\"pre\")\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "print('x_train shape:', X_train.shape)\n",
    "print('x_test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f15e4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 128)         384       \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 128)               99072     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 99,714\n",
      "Trainable params: 99,714\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build model\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(GRU(128, dropout=0.2)) #, recurrent_dropout=0.5\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy',f1_m])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e1c6018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-09 14:50:33.064704: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 4s 20ms/step - loss: 0.4861 - accuracy: 0.8194 - f1_m: 0.8224 - val_loss: 0.4885 - val_accuracy: 0.8082 - val_f1_m: 0.8085\n",
      "Epoch 2/5\n",
      "79/79 [==============================] - 1s 13ms/step - loss: 0.4480 - accuracy: 0.8246 - f1_m: 0.8240 - val_loss: 0.4497 - val_accuracy: 0.8051 - val_f1_m: 0.8070\n",
      "Epoch 3/5\n",
      "79/79 [==============================] - 1s 14ms/step - loss: 0.4144 - accuracy: 0.8294 - f1_m: 0.8295 - val_loss: 0.4278 - val_accuracy: 0.8082 - val_f1_m: 0.8085\n",
      "Epoch 4/5\n",
      "79/79 [==============================] - 1s 13ms/step - loss: 0.3920 - accuracy: 0.8254 - f1_m: 0.8255 - val_loss: 0.4239 - val_accuracy: 0.8146 - val_f1_m: 0.8143\n",
      "Epoch 5/5\n",
      "79/79 [==============================] - 1s 13ms/step - loss: 0.3888 - accuracy: 0.8278 - f1_m: 0.8287 - val_loss: 0.4210 - val_accuracy: 0.8209 - val_f1_m: 0.8194\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4210 - accuracy: 0.8209 - f1_m: 0.8194\n",
      "Test score: 0.421027272939682\n",
      "Test accuracy: 0.8209191560745239\n",
      "Test f1 score: 0.8193548917770386\n"
     ]
    }
   ],
   "source": [
    "# train, validate, save\n",
    "print('Train...')\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=5,\n",
    "          validation_data=(X_test, y_test))\n",
    "\n",
    "model.save(\"ModelWeights/sent-sum_GRU.h5\")\n",
    "\n",
    "score, acc, f1 = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n",
    "print('Test f1 score:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "77c431ae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: /data/ProcessedNYT/all_medicine.txt\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.4517 - accuracy: 0.7637 - f1_m: 0.7637\n",
      "Test score: 0.45168182253837585\n",
      "Test accuracy: 0.7637178301811218\n",
      "Test f1 score: 0.7636842727661133\n",
      "Evaluating: /data/ProcessedNYT/all_education.txt\n",
      "60/60 [==============================] - 0s 6ms/step - loss: 0.4468 - accuracy: 0.7752 - f1_m: 0.7741\n",
      "Test score: 0.44678205251693726\n",
      "Test accuracy: 0.7751572132110596\n",
      "Test f1 score: 0.774088442325592\n",
      "Evaluating: /data/ProcessedNYT/all_finance.txt\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.3947 - accuracy: 0.8318 - f1_m: 0.8306\n",
      "Test score: 0.3947012424468994\n",
      "Test accuracy: 0.8317994475364685\n",
      "Test f1 score: 0.8306416869163513\n",
      "Evaluating: /data/ProcessedNYT/all_law.txt\n",
      "113/113 [==============================] - 1s 6ms/step - loss: 0.5004 - accuracy: 0.7567 - f1_m: 0.7574\n",
      "Test score: 0.5004138946533203\n",
      "Test accuracy: 0.7566889524459839\n",
      "Test f1 score: 0.7573893070220947\n",
      "Evaluating: /data/ProcessedNYT/all_military.txt\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.4715 - accuracy: 0.7914 - f1_m: 0.7914\n",
      "Test score: 0.4715084135532379\n",
      "Test accuracy: 0.7913801074028015\n",
      "Test f1 score: 0.7913931608200073\n",
      "Evaluating: /data/ProcessedNYT/all_politics.txt\n",
      "220/220 [==============================] - 1s 6ms/step - loss: 0.4879 - accuracy: 0.7841 - f1_m: 0.7838\n",
      "Test score: 0.4878956973552704\n",
      "Test accuracy: 0.7841346859931946\n",
      "Test f1 score: 0.7837513089179993\n"
     ]
    }
   ],
   "source": [
    "# evaluating the model, using data from different topics/year\n",
    "for idx,df in enumerate(list_of_dfs):\n",
    "    \n",
    "    print('Evaluating:',list_of_files[idx])\n",
    "    \n",
    "    labels = df[0].values\n",
    "    labels = pd.get_dummies(labels).to_numpy()\n",
    "    X_sent_sum = df[4].apply(literal_eval)    \n",
    "    X_test = sequence.pad_sequences(X_sent_sum, maxlen=maxlen)\n",
    "    \n",
    "    score, acc, f1 = model.evaluate(X_test, labels, batch_size=batch_size)\n",
    "    print('Test score:', score)\n",
    "    print('Test accuracy:', acc)\n",
    "    print('Test f1 score:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad08f0d7",
   "metadata": {},
   "source": [
    "# Extended Model: Sent_compound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fdc61528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "2520 train sequences\n",
      "631 test sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (2520, 100)\n",
      "x_test shape: (631, 100)\n"
     ]
    }
   ],
   "source": [
    "# load and define data\n",
    "X_sent_com = train_df[3].apply(literal_eval)\n",
    "labels = train_df[0].values\n",
    "labels = pd.get_dummies(labels).to_numpy()\n",
    "\n",
    "print('Loading data...')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sent_com, labels, test_size=val_ratio, random_state=seed) \n",
    "\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen, dtype = np.float32)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen, dtype = np.float32)\n",
    "print('x_train shape:', X_train.shape)\n",
    "print('x_test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e01f10cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 128)               12928     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,186\n",
      "Trainable params: 13,186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build model\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape = (100, ))) #input shape as 100\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy', f1_m])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3d2d658a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Epoch 1/5\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 0.5313 - accuracy: 0.7944 - f1_m: 0.7946 - val_loss: 0.4650 - val_accuracy: 0.8082 - val_f1_m: 0.8085\n",
      "Epoch 2/5\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.4275 - accuracy: 0.8274 - f1_m: 0.8277 - val_loss: 0.4553 - val_accuracy: 0.8082 - val_f1_m: 0.8085\n",
      "Epoch 3/5\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.4154 - accuracy: 0.8274 - f1_m: 0.8277 - val_loss: 0.4528 - val_accuracy: 0.8082 - val_f1_m: 0.8085\n",
      "Epoch 4/5\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.4082 - accuracy: 0.8274 - f1_m: 0.8277 - val_loss: 0.4503 - val_accuracy: 0.8082 - val_f1_m: 0.8085\n",
      "Epoch 5/5\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.4015 - accuracy: 0.8274 - f1_m: 0.8274 - val_loss: 0.4486 - val_accuracy: 0.8082 - val_f1_m: 0.8085\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4486 - accuracy: 0.8082 - f1_m: 0.8085\n",
      "Test score: 0.44856879115104675\n",
      "Test accuracy: 0.8082408905029297\n",
      "Test f1 score: 0.8084918260574341\n"
     ]
    }
   ],
   "source": [
    "# train, validate, save\n",
    "print('Train...')\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=5,\n",
    "          validation_data=(X_test, y_test))\n",
    "\n",
    "model.save(\"ModelWeights/sent-com.h5\")\n",
    "\n",
    "score, acc, f1 = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n",
    "print('Test f1 score:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4f3e515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: /data/ProcessedNYT/all_medicine.txt\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.5129 - accuracy: 0.7368 - f1_m: 0.7372\n",
      "Test score: 0.512866735458374\n",
      "Test accuracy: 0.7368420958518982\n",
      "Test f1 score: 0.7372080087661743\n",
      "Evaluating: /data/ProcessedNYT/all_education.txt\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.5157 - accuracy: 0.7296 - f1_m: 0.7294\n",
      "Test score: 0.5157416462898254\n",
      "Test accuracy: 0.7295597195625305\n",
      "Test f1 score: 0.7293749451637268\n",
      "Evaluating: /data/ProcessedNYT/all_finance.txt\n",
      "99/99 [==============================] - 0s 4ms/step - loss: 0.4054 - accuracy: 0.8235 - f1_m: 0.8234\n",
      "Test score: 0.4053676426410675\n",
      "Test accuracy: 0.8235480785369873\n",
      "Test f1 score: 0.8234216570854187\n",
      "Evaluating: /data/ProcessedNYT/all_law.txt\n",
      "113/113 [==============================] - 0s 4ms/step - loss: 0.5564 - accuracy: 0.7352 - f1_m: 0.7373\n",
      "Test score: 0.5563758611679077\n",
      "Test accuracy: 0.7352285385131836\n",
      "Test f1 score: 0.7372786998748779\n",
      "Evaluating: /data/ProcessedNYT/all_military.txt\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.4947 - accuracy: 0.7983 - f1_m: 0.8007\n",
      "Test score: 0.49473652243614197\n",
      "Test accuracy: 0.7982577085494995\n",
      "Test f1 score: 0.8007245659828186\n",
      "Evaluating: /data/ProcessedNYT/all_politics.txt\n",
      "220/220 [==============================] - 1s 4ms/step - loss: 0.5211 - accuracy: 0.7773 - f1_m: 0.7783\n",
      "Test score: 0.5210676193237305\n",
      "Test accuracy: 0.7772863507270813\n",
      "Test f1 score: 0.778266966342926\n"
     ]
    }
   ],
   "source": [
    "# evaluating the model, using data from different topics/year\n",
    "for idx,df in enumerate(list_of_dfs):\n",
    "    \n",
    "    print('Evaluating:',list_of_files[idx])\n",
    "    \n",
    "    labels = df[0].values\n",
    "    labels = pd.get_dummies(labels).to_numpy()\n",
    "    X_sent_com = df[3].apply(literal_eval)\n",
    "    X_sent_com = [np.array(x) for x in X_sent_com]\n",
    "    \n",
    "    X_test = sequence.pad_sequences(X_sent_com, maxlen=maxlen, dtype = np.float32)\n",
    "    X_test = X_test.reshape(len(X_test),maxlen,1)    \n",
    "    \n",
    "    score, acc, f1 = model.evaluate(X_test, labels, batch_size=batch_size)\n",
    "    print('Test score:', score)\n",
    "    print('Test accuracy:', acc)\n",
    "    print('Test f1 score:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33e41b4",
   "metadata": {},
   "source": [
    "# Extended Model: POS counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "94672b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "x_train shape: (2520, 4500, 1)\n",
      "x_test shape: (631, 4500, 1)\n"
     ]
    }
   ],
   "source": [
    "# load and define data\n",
    "labels = train_df[0].values\n",
    "labels = pd.get_dummies(labels).to_numpy()\n",
    "x_pos = train_df[5].apply(literal_eval)\n",
    "max_features = len(le.classes_)\n",
    "\n",
    "# extra-pre-processing step\n",
    "X_pos = []\n",
    "for x in x_pos:\n",
    "    art_pos = pos_count_article(counter_pos(x_pos[0]),list(le.classes_)).reshape(-1,1)\n",
    "    X_pos.append(art_pos)\n",
    "X_pos = np.stack(X_pos)\n",
    "\n",
    "print('Loading data...')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pos, labels, test_size=val_ratio, random_state=seed) \n",
    "\n",
    "print('x_train shape:', X_train.shape)\n",
    "print('x_test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3c6cc0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 128)               576128    \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 576,386\n",
      "Trainable params: 576,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build model\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape = (4500, )))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy', f1_m])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2dc01cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Epoch 1/5\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 0.5154 - accuracy: 0.8274 - f1_m: 0.8275 - val_loss: 0.5009 - val_accuracy: 0.8082 - val_f1_m: 0.8085\n",
      "Epoch 2/5\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.5133 - accuracy: 0.8274 - f1_m: 0.8271 - val_loss: 0.4909 - val_accuracy: 0.8082 - val_f1_m: 0.8085\n",
      "Epoch 3/5\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.4788 - accuracy: 0.8274 - f1_m: 0.8270 - val_loss: 0.5124 - val_accuracy: 0.8082 - val_f1_m: 0.8085\n",
      "Epoch 4/5\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.4817 - accuracy: 0.8274 - f1_m: 0.8275 - val_loss: 0.5429 - val_accuracy: 0.8082 - val_f1_m: 0.8085\n",
      "Epoch 5/5\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.4935 - accuracy: 0.8274 - f1_m: 0.8273 - val_loss: 0.4937 - val_accuracy: 0.8082 - val_f1_m: 0.8085\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4937 - accuracy: 0.8082 - f1_m: 0.8085\n",
      "Test score: 0.4937295913696289\n",
      "Test accuracy: 0.8082408905029297\n",
      "Test f1 score: 0.8084918260574341\n"
     ]
    }
   ],
   "source": [
    "# train, validate, save\n",
    "print('Train...')\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=5,\n",
    "          validation_data=(X_test,y_test))\n",
    "\n",
    "model.save(\"ModelWeights/pos-count.h5\")\n",
    "\n",
    "score, acc, f1 = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n",
    "print('Test f1 score:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "975504ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: /data/ProcessedNYT/all_medicine.txt\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.5822 - accuracy: 0.7368 - f1_m: 0.7372\n",
      "Test score: 0.5821709632873535\n",
      "Test accuracy: 0.7368420958518982\n",
      "Test f1 score: 0.7372080087661743\n",
      "Evaluating: /data/ProcessedNYT/all_education.txt\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.5915 - accuracy: 0.7296 - f1_m: 0.7294\n",
      "Test score: 0.5914919376373291\n",
      "Test accuracy: 0.7295597195625305\n",
      "Test f1 score: 0.7293749451637268\n",
      "Evaluating: /data/ProcessedNYT/all_finance.txt\n",
      "99/99 [==============================] - 0s 3ms/step - loss: 0.4688 - accuracy: 0.8235 - f1_m: 0.8234\n",
      "Test score: 0.46880000829696655\n",
      "Test accuracy: 0.8235480785369873\n",
      "Test f1 score: 0.8234216570854187\n",
      "Evaluating: /data/ProcessedNYT/all_law.txt\n",
      "113/113 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7352 - f1_m: 0.7373\n",
      "Test score: 0.6323300004005432\n",
      "Test accuracy: 0.7352285385131836\n",
      "Test f1 score: 0.7372786998748779\n",
      "Evaluating: /data/ProcessedNYT/all_military.txt\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7983 - f1_m: 0.8007\n",
      "Test score: 0.5041810274124146\n",
      "Test accuracy: 0.7982577085494995\n",
      "Test f1 score: 0.8007245659828186\n",
      "Evaluating: /data/ProcessedNYT/all_politics.txt\n",
      "220/220 [==============================] - 1s 3ms/step - loss: 0.5589 - accuracy: 0.7773 - f1_m: 0.7783\n",
      "Test score: 0.5588778257369995\n",
      "Test accuracy: 0.7772863507270813\n",
      "Test f1 score: 0.778266966342926\n"
     ]
    }
   ],
   "source": [
    "# evaluating the model, using data from different topics/year\n",
    "for idx,df in enumerate(list_of_dfs):\n",
    "    \n",
    "    print('Evaluating:',list_of_files[idx])\n",
    "    labels = df[0].values\n",
    "    labels = pd.get_dummies(labels).to_numpy()\n",
    "    X_pos = df[5].apply(literal_eval)\n",
    "\n",
    "    X_pos_test = []\n",
    "    for x in X_pos:\n",
    "        art_pos = pos_count_article(counter_pos(X_pos[0]),list(le.classes_)).reshape(-1,1)\n",
    "        X_pos_test.append(art_pos)\n",
    "    X_pos_test = np.stack(X_pos_test)\n",
    "    \n",
    "    score, acc, f1 = model.evaluate(X_pos_test, labels, batch_size=batch_size)\n",
    "    print('Test score:', score)\n",
    "    print('Test accuracy:', acc)\n",
    "    print('Test f1 score:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2475ab",
   "metadata": {},
   "source": [
    "# Extension: POS sequence-padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6604734d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "x_train shape: (2520, 5000, 1)\n",
      "x_test shape: (631, 5000, 1)\n"
     ]
    }
   ],
   "source": [
    "# load and define data\n",
    "labels = train_df[0].values\n",
    "labels = pd.get_dummies(labels).to_numpy()\n",
    "x_pos = train_df[5].apply(literal_eval)\n",
    "max_features = len(le.classes_)\n",
    "\n",
    "# extra-pre-processing step\n",
    "X_pos = []\n",
    "for x in x_pos:\n",
    "    art_pos = pad_article(x).reshape(-1,1)\n",
    "    X_pos.append(art_pos)\n",
    "X_pos = np.stack(X_pos)\n",
    "\n",
    "print('Loading data...')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pos, labels, test_size=val_ratio, random_state=seed) \n",
    "\n",
    "print('x_train shape:', X_train.shape)\n",
    "print('x_test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5bb7d3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 5000, 128)         5760      \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,914\n",
      "Trainable params: 38,914\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build model\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "#model.add(Dense(128, activation='relu', input_shape = (5000, )))\n",
    "model.add(Embedding(45, 128, input_length=5000))\n",
    "#model.add(Embedding(max_features, 128))\n",
    "model.add(SimpleRNN(128, dropout=0.2)) #, recurrent_dropout=0.5\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy', f1_m])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "289fc7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Epoch 1/5\n",
      "79/79 [==============================] - 523s 7s/step - loss: 0.4740 - accuracy: 0.8274 - f1_m: 0.8157 - val_loss: 0.4897 - val_accuracy: 0.8082 - val_f1_m: 0.8085\n",
      "Epoch 2/5\n",
      "79/79 [==============================] - 516s 7s/step - loss: 0.4597 - accuracy: 0.8274 - f1_m: 0.8274 - val_loss: 0.4897 - val_accuracy: 0.8082 - val_f1_m: 0.8085\n",
      "Epoch 3/5\n",
      "79/79 [==============================] - 520s 7s/step - loss: 0.4640 - accuracy: 0.8274 - f1_m: 0.8274 - val_loss: 0.4895 - val_accuracy: 0.8082 - val_f1_m: 0.8085\n",
      "Epoch 4/5\n",
      "79/79 [==============================] - 518s 7s/step - loss: 0.4621 - accuracy: 0.8274 - f1_m: 0.8274 - val_loss: 0.4900 - val_accuracy: 0.8082 - val_f1_m: 0.8085\n",
      "Epoch 5/5\n",
      "79/79 [==============================] - 525s 7s/step - loss: 0.4639 - accuracy: 0.8274 - f1_m: 0.8275 - val_loss: 0.4889 - val_accuracy: 0.8082 - val_f1_m: 0.8085\n",
      "20/20 [==============================] - 8s 406ms/step - loss: 0.4889 - accuracy: 0.8082 - f1_m: 0.8085\n",
      "Test score: 0.4889063537120819\n",
      "Test accuracy: 0.8082408905029297\n",
      "Test f1 score: 0.8084918260574341\n"
     ]
    }
   ],
   "source": [
    "# train, validate, save\n",
    "print('Train...')\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=5,\n",
    "          validation_data=(X_test,y_test))\n",
    "\n",
    "model.save(\"ModelWeights/pos-padded.h5\")\n",
    "\n",
    "score, acc, f1 = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n",
    "print('Test f1 score:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "84cd2114",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: /data/ProcessedNYT/all_medicine.txt\n",
      "56/56 [==============================] - 23s 406ms/step - loss: 0.5899 - accuracy: 0.7368 - f1_m: 0.7372\n",
      "Test score: 0.5898562073707581\n",
      "Test accuracy: 0.7368420958518982\n",
      "Test f1 score: 0.7372080087661743\n",
      "Evaluating: /data/ProcessedNYT/all_education.txt\n",
      "60/60 [==============================] - 26s 426ms/step - loss: 0.6002 - accuracy: 0.7296 - f1_m: 0.7294\n",
      "Test score: 0.6001524925231934\n",
      "Test accuracy: 0.7295597195625305\n",
      "Test f1 score: 0.7293749451637268\n",
      "Evaluating: /data/ProcessedNYT/all_finance.txt\n",
      "99/99 [==============================] - 41s 413ms/step - loss: 0.4673 - accuracy: 0.8235 - f1_m: 0.8234\n",
      "Test score: 0.46726369857788086\n",
      "Test accuracy: 0.8235480785369873\n",
      "Test f1 score: 0.8234216570854187\n",
      "Evaluating: /data/ProcessedNYT/all_law.txt\n",
      "113/113 [==============================] - 50s 437ms/step - loss: 0.5921 - accuracy: 0.7352 - f1_m: 0.7373\n",
      "Test score: 0.5921376347541809\n",
      "Test accuracy: 0.7352285385131836\n",
      "Test f1 score: 0.7372786998748779\n",
      "Evaluating: /data/ProcessedNYT/all_military.txt\n",
      "69/69 [==============================] - 28s 412ms/step - loss: 0.5030 - accuracy: 0.7983 - f1_m: 0.8007\n",
      "Test score: 0.5030216574668884\n",
      "Test accuracy: 0.7982577085494995\n",
      "Test f1 score: 0.8007245659828186\n",
      "Evaluating: /data/ProcessedNYT/all_politics.txt\n",
      "220/220 [==============================] - 92s 419ms/step - loss: 0.5327 - accuracy: 0.7773 - f1_m: 0.7783\n",
      "Test score: 0.532672643661499\n",
      "Test accuracy: 0.7772863507270813\n",
      "Test f1 score: 0.778266966342926\n"
     ]
    }
   ],
   "source": [
    "# evaluating the model, using data from different topics/year\n",
    "for idx,df in enumerate(list_of_dfs):\n",
    "    \n",
    "    print('Evaluating:',list_of_files[idx])\n",
    "    \n",
    "    labels = df[0].values\n",
    "    labels = pd.get_dummies(labels).to_numpy()\n",
    "    X_pos = df[5].apply(literal_eval)\n",
    "\n",
    "    X_pos_test = []\n",
    "\n",
    "    for x in X_pos:\n",
    "        art_pos = pad_article(x).reshape(-1,1)\n",
    "        X_pos_test.append(art_pos)\n",
    "    X_pos_test = np.stack(X_pos_test)   \n",
    "    \n",
    "    score, acc, f1 = model.evaluate(X_pos_test, labels, batch_size=batch_size)\n",
    "    print('Test score:', score)\n",
    "    print('Test accuracy:', acc)\n",
    "    print('Test f1 score:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc51cfed",
   "metadata": {},
   "source": [
    "# Extension: POS sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "447a0209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "x_train shape: (2508, 2000, 1)\n",
      "x_test shape: (628, 2000, 1)\n"
     ]
    }
   ],
   "source": [
    "# load and define data\n",
    "labels = train_df[0]\n",
    "x_pos = train_df[5].apply(literal_eval)\n",
    "max_features = len(le.classes_)\n",
    "\n",
    "# extra pre-processing step\n",
    "N = 2000\n",
    "error = []\n",
    "x_pos_list = []\n",
    "for i,x in enumerate(x_pos):\n",
    "    flatten = [item for sublist in x for item in sublist]\n",
    "    try:\n",
    "        flatten = le.transform(flatten)\n",
    "        if len(flatten) < N:\n",
    "            x = np.concatenate([flatten,np.zeros(N - len(flatten))])\n",
    "        else:\n",
    "            x = flatten[:N]\n",
    "        x = np.array(x).reshape(-1,1)\n",
    "        x_pos_list.append(x) \n",
    "    except:\n",
    "        error.append(i)\n",
    "labels = labels.drop(labels.index[error])\n",
    "X_pos = np.stack(x_pos_list) \n",
    "labels = pd.get_dummies(labels).to_numpy()\n",
    "\n",
    "print('Loading data...')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pos, labels, test_size=val_ratio, random_state=seed) \n",
    "\n",
    "print('x_train shape:', X_train.shape)\n",
    "print('x_test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94d1d97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 128)         5760      \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 128)               32896     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,914\n",
      "Trainable params: 38,914\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-09 15:44:52.361579: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-09 15:44:53.139896: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10413 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:84:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "# build model\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "#model.add(Dense(128, activation='relu', input_shape = (2000, )))\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(SimpleRNN(128, dropout=0.2)) #, recurrent_dropout=0.5\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy', f1_m])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "703f4768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Epoch 1/5\n",
      "79/79 [==============================] - 182s 2s/step - loss: 0.4712 - accuracy: 0.8250 - f1_m: 0.8250 - val_loss: 0.4855 - val_accuracy: 0.8121 - val_f1_m: 0.8128\n",
      "Epoch 2/5\n",
      "79/79 [==============================] - 176s 2s/step - loss: 0.4687 - accuracy: 0.8254 - f1_m: 0.8248 - val_loss: 0.4850 - val_accuracy: 0.8121 - val_f1_m: 0.8128\n",
      "Epoch 3/5\n",
      "79/79 [==============================] - 180s 2s/step - loss: 0.4676 - accuracy: 0.8254 - f1_m: 0.8261 - val_loss: 0.4840 - val_accuracy: 0.8121 - val_f1_m: 0.8128\n",
      "Epoch 4/5\n",
      "79/79 [==============================] - 177s 2s/step - loss: 0.4645 - accuracy: 0.8254 - f1_m: 0.8254 - val_loss: 0.4875 - val_accuracy: 0.8121 - val_f1_m: 0.8128\n",
      "Epoch 5/5\n",
      "79/79 [==============================] - 179s 2s/step - loss: 0.4648 - accuracy: 0.8254 - f1_m: 0.8261 - val_loss: 0.4865 - val_accuracy: 0.8121 - val_f1_m: 0.8128\n",
      "20/20 [==============================] - 3s 167ms/step - loss: 0.4865 - accuracy: 0.8121 - f1_m: 0.8128\n",
      "Test score: 0.4864695370197296\n",
      "Test accuracy: 0.8121019005775452\n",
      "Test f1 score: 0.8128124475479126\n"
     ]
    }
   ],
   "source": [
    "# train, validate, save\n",
    "print('Train...')\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=5,\n",
    "          validation_data=(X_test,y_test))\n",
    "\n",
    "model.save(\"ModelWeights/pos-seq.h5\")\n",
    "\n",
    "score, acc, f1 = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n",
    "print('Test f1 score:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5227aa1c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: /data/ProcessedNYT/all_medicine.txt\n",
      "56/56 [==============================] - 10s 176ms/step - loss: 0.5808 - accuracy: 0.7361 - f1_m: 0.7368\n",
      "Test score: 0.5808092951774597\n",
      "Test accuracy: 0.7361032962799072\n",
      "Test f1 score: 0.7368462681770325\n",
      "Evaluating: /data/ProcessedNYT/all_education.txt\n",
      "60/60 [==============================] - 11s 183ms/step - loss: 0.5890 - accuracy: 0.7290 - f1_m: 0.7286\n",
      "Test score: 0.5890154838562012\n",
      "Test accuracy: 0.7289915680885315\n",
      "Test f1 score: 0.7286457419395447\n",
      "Evaluating: /data/ProcessedNYT/all_finance.txt\n",
      "98/98 [==============================] - 18s 179ms/step - loss: 0.4726 - accuracy: 0.8227 - f1_m: 0.8227\n",
      "Test score: 0.47263115644454956\n",
      "Test accuracy: 0.8227040767669678\n",
      "Test f1 score: 0.822704017162323\n",
      "Evaluating: /data/ProcessedNYT/all_law.txt\n",
      "112/112 [==============================] - 20s 174ms/step - loss: 0.5841 - accuracy: 0.7337 - f1_m: 0.7343\n",
      "Test score: 0.5840604305267334\n",
      "Test accuracy: 0.7336697578430176\n",
      "Test f1 score: 0.7343005537986755\n",
      "Evaluating: /data/ProcessedNYT/all_military.txt\n",
      "68/68 [==============================] - 13s 184ms/step - loss: 0.5060 - accuracy: 0.7966 - f1_m: 0.7983\n",
      "Test score: 0.5059718489646912\n",
      "Test accuracy: 0.796570897102356\n",
      "Test f1 score: 0.79825359582901\n",
      "Evaluating: /data/ProcessedNYT/all_politics.txt\n",
      "219/219 [==============================] - 38s 173ms/step - loss: 0.5315 - accuracy: 0.7763 - f1_m: 0.7773\n",
      "Test score: 0.5315024256706238\n",
      "Test accuracy: 0.7762969136238098\n",
      "Test f1 score: 0.7772545218467712\n"
     ]
    }
   ],
   "source": [
    "# evaluating the model, using data from different topics/year\n",
    "for idx,df in enumerate(list_of_dfs):\n",
    "    \n",
    "    print('Evaluating:',list_of_files[idx])\n",
    "\n",
    "    labels = df[0]\n",
    "    x_pos = df[5].apply(literal_eval)    \n",
    "    x_pos_list = [] \n",
    "    error = []\n",
    "\n",
    "    for i,x in enumerate(x_pos):\n",
    "        flatten = [item for sublist in x for item in sublist]\n",
    "        try:\n",
    "            flatten = le.transform(flatten)\n",
    "            if len(flatten) < N:\n",
    "                x = np.concatenate([flatten,np.zeros(N - len(flatten))])\n",
    "            else:\n",
    "                x = flatten[:N]\n",
    "            x = np.array(x).reshape(-1,1)\n",
    "            x_pos_list.append(x) \n",
    "        except:\n",
    "            error.append(i)\n",
    "\n",
    "    labels = labels.drop(labels.index[error])\n",
    "    X_pos_test = np.stack(x_pos_list)       \n",
    "    labels = pd.get_dummies(labels).to_numpy()\n",
    "\n",
    "    score, acc, f1 = model.evaluate(X_pos_test, labels, batch_size=batch_size)\n",
    "    print('Test score:', score)\n",
    "    print('Test accuracy:', acc)\n",
    "    print('Test f1 score:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90486307",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1c2b59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ba5bd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
