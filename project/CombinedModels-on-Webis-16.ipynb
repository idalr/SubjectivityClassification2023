{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22dc8b64",
   "metadata": {},
   "source": [
    "***Description***\n",
    "\n",
    "<div> In this notebook, I test one of the models (`af6_sent_pos`) on the Webis-editorial-16 corpus. The corpus itself only 1 (aka editorial) label; however, this is for the purpose of testing the model on different dataset, other than NYTAC. The model makes predictions based on 3 inputs: fine-grained 6 argumentation features, sentence-level sentiment, and sentence-level POS tags counts. Various helper functions are installed and the model is imported. The result is printed on the last cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2511ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/users/rldall/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/users/rldall/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/users/rldall/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package tagsets to\n",
      "[nltk_data]     /home/users/rldall/nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# All packages\n",
    "import nltk\n",
    "import numpy as np\n",
    "import glob, os\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from collections import Counter\n",
    "from glob import glob\n",
    "from nltk import word_tokenize, StanfordTagger\n",
    "from nltk.data import load\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from sklearn import preprocessing\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
    "\n",
    "# NLTK\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('tagsets')\n",
    "\n",
    "# import VADER\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# import POS tag_dict and label encoder\n",
    "tagdict = load('help/tagsets/upenn_tagset.pickle')\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(list(tagdict.keys()))\n",
    "\n",
    "# keras\n",
    "import keras\n",
    "from keras import Input, Model\n",
    "from keras import backend as K\n",
    "from keras.constraints import maxnorm\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional, Concatenate, Embedding, Dense, Dropout, InputLayer, Reshape, SimpleRNN, BatchNormalization, TimeDistributed, Lambda, Activation, MaxPooling1D\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0138f8",
   "metadata": {},
   "source": [
    "# Test on Webis-editorial-16 corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f11ca10",
   "metadata": {},
   "source": [
    "Note: All articles in the Webis are editorials, but this is for the purpose of testing on different publishers - to see how our ML models generalize outside the NYT corpus, which they were trained on (Finance, Years 1996 & 2005)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969eb1e5",
   "metadata": {},
   "source": [
    "#### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3d95d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/data/ArgFeatModel/corpus-webis-editorials-16/annotated-txt/split-by-portal-final'\n",
    "publist = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07de56b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_df(filepath):\n",
    "    main_df = pd.DataFrame(columns=['unit'])\n",
    "\n",
    "#    for filename in glob.glob(os.path.join(path, '*.txt')): ###\n",
    "    with open(os.path.join(os.getcwd(), filepath), 'r') as f: \n",
    "        lines = f.readlines()\n",
    "            #lines.remove('-1\\tpar-sep\\t\\n') ###\n",
    "        this_lines_df = pd.DataFrame(lines, columns=['unit'])\n",
    "        main_df = pd.concat([main_df,this_lines_df]) ### ###\n",
    "        \n",
    "    main_df = main_df['unit'].str.split('\\t',expand=True)\n",
    "    main_df = main_df[[2]].replace('\\n','', regex=True)\n",
    "\n",
    "    return ' '.join(main_df[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f758905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all publishers into df and keep in list\n",
    "\n",
    "pub_df_list = []\n",
    "for pub in publist:\n",
    "    pub_text = []\n",
    "    for file in glob(os.path.join(path+'/'+pub, '*.txt')):\n",
    "        text = ''\n",
    "        text = extract_df(file)\n",
    "        pub_text.append(text)\n",
    "    pub_df = pd.DataFrame({0:1,1:pub_text})\n",
    "    pub_df_list.append(pub_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f39597a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to tokenzie text\n",
    "def tokenize_input(df):\n",
    "    # import data\n",
    "    text_series = df[1]\n",
    "    text_token = []\n",
    "    # tokenize sentences\n",
    "    for t in text_series:\n",
    "        sent_token = sent_tokenize(t)\n",
    "        text_token.append(sent_token)\n",
    "    # new column\n",
    "    df[2] = text_token\n",
    "    return df\n",
    "\n",
    "# Helper function for padding\n",
    "def padding_X(X):    \n",
    "    return sequence.pad_sequences(X, maxlen=100)\n",
    "\n",
    "# Helper functions to extract VADER sentiment\n",
    "def format_sent(compound_score):\n",
    "    polarity = 0\n",
    "    if(compound_score>= 0.05):\n",
    "        polarity = 1\n",
    "    elif(compound_score<= -0.05):\n",
    "        polarity = -1\n",
    "    return polarity\n",
    "\n",
    "def get_scores(text):\n",
    "    scores = sid.polarity_scores(text)\n",
    "    return np.array([scores.get(s) for s in scores])\n",
    "\n",
    "def get_sentiment(df,series_col,df_idx):\n",
    "    series = df[series_col]\n",
    "    error_list = []\n",
    "    compound_list = []\n",
    "    sum_list = []\n",
    "    \n",
    "#    for article in series:\n",
    "    for idx in range(len(series)):\n",
    "        article = series.iloc[idx]       \n",
    "        try:\n",
    "            scores = [get_scores(text) for text in article]\n",
    "            compound_list.append([s[-1] for s in scores])        \n",
    "            sum_list.append([format_sent(s[-1]) for s in scores])\n",
    "            \n",
    "        except:\n",
    "            print('Error line:',idx)\n",
    "            error_list.append(idx)\n",
    "\n",
    "    # new column\n",
    "    df['sent_compound'] = compound_list\n",
    "    df['sent_sum'] = sum_list\n",
    "    \n",
    "    df = df.drop(error_list)\n",
    "#    df.to_csv(list_of_files[df_idx],sep='\\t',header=False,index=False)\n",
    "#    print('Saved\\t', list_of_files[df_idx].split('/')[-1])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Helper functions to extract POS tags\n",
    "def predict_pos(text):\n",
    "    text_tok = nltk.word_tokenize(text)\n",
    "    return [word_class for word, word_class in nltk.pos_tag(text_tok)]\n",
    "\n",
    "def get_pos(df,series_col,df_idx):\n",
    "    series = df[series_col]\n",
    "    error_list = []\n",
    "    pos_list = []\n",
    "    for idx in range(len(series)):\n",
    "        article = series.iloc[idx]\n",
    "        try:\n",
    "            article_pos = [predict_pos(sent) for sent in article]\n",
    "            pos_list.append(article_pos)\n",
    "        except:\n",
    "            print('Error line:',idx)\n",
    "            error_list.append(idx)\n",
    "    # new column\n",
    "    df['pos'] = pos_list\n",
    "    df = df.drop(error_list)\n",
    "#    df.to_csv(list_of_files[df_idx],sep='\\t',header=False,index=False)\n",
    "#    print('Saved\\t', list_of_files[df_idx].split('/')[-1])\n",
    "    return df\n",
    "\n",
    "# Helper function for POS tagger\n",
    "# POS count\n",
    "def counter_pos(article):\n",
    "    a =[]  \n",
    "    for idx,sent_pos in enumerate(article):\n",
    "        count_pos = Counter(sent_pos)\n",
    "        a.append(dict(count_pos))\n",
    "    return a\n",
    "        \n",
    "def pos_count_article(counter_result, pos_index):\n",
    "    article_pos_count_array = np.zeros(shape=(MAXLEN,len(le.classes_)))\n",
    "    for art_i,sent_pos_count in enumerate(counter_result):\n",
    "        if art_i >= MAXLEN:        \n",
    "            pass\n",
    "        else:\n",
    "            for pos_item in sent_pos_count:\n",
    "                try:\n",
    "                    item_idx = pos_index.index(pos_item)\n",
    "                    article_pos_count_array[art_i,item_idx] = sent_pos_count.get(pos_item)\n",
    "                except:\n",
    "                    pass\n",
    "    return article_pos_count_array\n",
    "\n",
    "# Helper function for padding\n",
    "def padding_X(X):    \n",
    "    return sequence.pad_sequences(X, maxlen=100)\n",
    "\n",
    "# Helper functions to extract argfeat prediction\n",
    "def load_model(name):\n",
    "    # name in form of numlabel_epochs\n",
    "    for f in os.listdir('/data/ArgFeatModel/ModelWeights/'):\n",
    "        if f.startswith('saved_weights_'+name):\n",
    "            model_path = ('/data/ArgFeatModel/ModelWeights/'+f)\n",
    "    loaded_model =  BertForSequenceClassification.from_pretrained('bert-base-cased',num_labels = int(name[0]))\n",
    "    loaded_model.load_state_dict(torch.load(model_path))\n",
    "    loaded_model.eval()\n",
    "    loaded_model.to(device)\n",
    "    return loaded_model\n",
    "\n",
    "# sent preprocessing\n",
    "def get_sent_argfeat(sent,tokenizer,model):\n",
    "    # token IDs and attention mask for inference on the new sentence\n",
    "    test_ids = []\n",
    "    test_attention_mask = []\n",
    "    # apply the tokenizer\n",
    "    encoding = tokenizer.encode_plus(\n",
    "                        sent,\n",
    "                        add_special_tokens = True,\n",
    "                        max_length = 256,\n",
    "                        padding = True,\n",
    "                        return_attention_mask = True,\n",
    "                        return_tensors = 'pt'\n",
    "                   )\n",
    "    # extract IDs and attention mask\n",
    "    test_ids.append(encoding['input_ids'])\n",
    "    test_attention_mask.append(encoding['attention_mask'])\n",
    "    test_ids = torch.cat(test_ids, dim = 0)\n",
    "    test_attention_mask = torch.cat(test_attention_mask, dim = 0)\n",
    "    with torch.no_grad():\n",
    "        output = model(test_ids.to(device), token_type_ids = None, attention_mask = test_attention_mask.to(device))\n",
    "    # get prediction\n",
    "    pred = np.argmax(output.logits.cpu().numpy()).flatten().item()\n",
    "    return pred\n",
    "\n",
    "def get_argfeat(df,series_col,model, max_sent, df_idx):\n",
    "    print ('Extracting from', list_of_files[df_idx])\n",
    "    series = df[series_col]\n",
    "    error_list = []\n",
    "    count_long = 0\n",
    "    pred_list = []\n",
    "    error_list = []\n",
    "    for idx in range(len(series)):\n",
    "        article = series.iloc[idx]\n",
    "        if len(article) > max_sent:\n",
    "            try:\n",
    "                pred_text = [get_sent_argfeat(sent,tokenizer,model)+1 for sent in article[:max_sent]]\n",
    "                count_long += 1\n",
    "            except:\n",
    "                print('Error line:',idx)\n",
    "                error_list.append(idx)\n",
    "        else:\n",
    "            try:\n",
    "                pred_text = [get_sent_argfeat(sent,tokenizer,model)+1 for sent in article]# + [0] * (N-len(sent_token))\n",
    "            except:\n",
    "                print('Error line:',idx)\n",
    "                error_list.append(idx)\n",
    "        pred_list.append(pred_text)\n",
    "    print('long articles:',count_long,'from',len(df))\n",
    "    print('percent of long articles:', count_long/(count_long+len(df)))\n",
    "    flat_list = [item for sublist in pred_list for item in sublist]\n",
    "    num_label = max(flat_list)\n",
    "    # new column\n",
    "    df[str('argfeat'+str(num_label))] = pred_list\n",
    "    df = df.drop(error_list)\n",
    "#    df.to_csv(list_of_files[df_idx],sep='\\t',header=False,index=False)\n",
    "#    print('Saved\\t', list_of_files[df_idx].split('/')[-1])\n",
    "    return df\n",
    "\n",
    "# Helper function to transform test data\n",
    "def process_test_df(df,af3=False,af6=False,sent=False,pos=False):\n",
    "    out = []\n",
    "\n",
    "    # argfeat   \n",
    "    if af3:\n",
    "        x_argfeat3 = df.iloc[:, 6]\n",
    "        X_argfeat3 = padding_X(x_argfeat3)\n",
    "        out.append(X_argfeat3)\n",
    "    \n",
    "    if af6:\n",
    "        x_argfeat6 = df.iloc[:, 7]\n",
    "        X_argfeat6 = padding_X(x_argfeat6)\n",
    "        out.append(X_argfeat6)\n",
    "\n",
    "    # sent_sum\n",
    "    if sent:\n",
    "        x_sent = df.iloc[:, 4]\n",
    "        X_sent = padding_X(x_sent)\n",
    "        out.append(X_sent)\n",
    "\n",
    "    # pos count\n",
    "    if pos:        \n",
    "        x_pos = df.iloc[:, 5]\n",
    "        x_pos_list = [] \n",
    "        for x in x_pos: \n",
    "            art_pos = pos_count_article(counter_pos(x_pos[0]),list(le.classes_)).reshape(-1,1)\n",
    "            x_pos_list.append(art_pos) \n",
    "        X_pos = np.stack(x_pos_list) \n",
    "        X_pos = X_pos.reshape(X_pos.shape[0],X_pos.shape[1]) \n",
    "        out.append(X_pos)\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9327ebaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading sent...\n",
      "loading pos...\n",
      "loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading argfeat3...\n",
      "Extracting from guardian\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/rldall/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2364: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "long articles: 1 from 100\n",
      "percent of long articles: 0.009900990099009901\n",
      "Extracting from foxnews\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/rldall/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2364: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "long articles: 1 from 100\n",
      "percent of long articles: 0.009900990099009901\n",
      "Extracting from aljazeera\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/rldall/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2364: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "long articles: 0 from 100\n",
      "percent of long articles: 0.0\n",
      "loading argfeat6...\n",
      "Extracting from guardian\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/rldall/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2364: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "long articles: 1 from 100\n",
      "percent of long articles: 0.009900990099009901\n",
      "Extracting from foxnews\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/rldall/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2364: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "long articles: 1 from 100\n",
      "percent of long articles: 0.009900990099009901\n",
      "Extracting from aljazeera\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/rldall/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2364: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "long articles: 0 from 100\n",
      "percent of long articles: 0.0\n"
     ]
    }
   ],
   "source": [
    "MAXLEN= 100\n",
    "PAD_VALUE = 80\n",
    "MAX_SENT_PAD = 50\n",
    "MAX_SENTS = MAXLEN\n",
    "MAX_POS_PAD = 2000\n",
    "list_of_files = publist\n",
    "\n",
    "# transform files into dataframes\n",
    "list_of_dataframes = [tokenize_input(file) for file in pub_df_list]\n",
    "\n",
    "# get sentiment columns\n",
    "print('loading sent...')\n",
    "list_of_sent_dfs = [get_sentiment(df,2,df_idx) for df_idx,df in enumerate(list_of_dataframes)]\n",
    "\n",
    "# get pos columns\n",
    "print('loading pos...')\n",
    "list_of_pos_dfs = [get_pos(df,2,df_idx) for df_idx,df in enumerate(list_of_dataframes)]\n",
    "\n",
    "# specify GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-cased')\n",
    "\n",
    "# import arg-feat model\n",
    "print('loading model...')\n",
    "model3 = load_model(\"3_5\")\n",
    "model6 = load_model(\"6_3\")\n",
    "\n",
    "# get argfeat columns\n",
    "print('loading argfeat3...')\n",
    "list_of_argfeat3_dfs = [get_argfeat(df,2, model3, MAX_SENTS, df_idx) for df_idx,df in enumerate(list_of_dataframes)]\n",
    "print('loading argfeat6...')\n",
    "list_of_argfeat6_dfs = [get_argfeat(df,2, model6, MAX_SENTS, df_idx) for df_idx,df in enumerate(list_of_dataframes)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bda12b",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dec85c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71654eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-13 15:04:14.147307: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-13 15:04:14.153333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8819 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:84:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "loaded_model3 = keras.models.load_model(\"ModelWeights/af3_sent_pos.h5\", custom_objects={'f1_m':f1_m}, compile=False)\n",
    "loaded_model3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',f1_m])\n",
    "loaded_model6 = keras.models.load_model(\"ModelWeights/af6_sent_pos.h5\", custom_objects={'f1_m':f1_m}, compile=False)\n",
    "loaded_model6.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',f1_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2d0cdbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: guardian\n",
      "4/4 [==============================] - 3s 410ms/step - loss: 0.7771 - accuracy: 0.6800 - f1_m: 0.7500\n",
      "Test score: 0.7770951986312866\n",
      "Test accuracy: 0.6800000071525574\n",
      "Test f1 score: 0.7499999403953552\n",
      "Evaluating: foxnews\n",
      "4/4 [==============================] - 2s 380ms/step - loss: 1.2478 - accuracy: 0.5300 - f1_m: 0.5157\n",
      "Test score: 1.2477526664733887\n",
      "Test accuracy: 0.5299999713897705\n",
      "Test f1 score: 0.5156784057617188\n",
      "Evaluating: aljazeera\n",
      "4/4 [==============================] - 2s 458ms/step - loss: 0.8426 - accuracy: 0.6200 - f1_m: 0.6015\n",
      "Test score: 0.8426142930984497\n",
      "Test accuracy: 0.6200000047683716\n",
      "Test f1 score: 0.6015151143074036\n"
     ]
    }
   ],
   "source": [
    "# cross-publishers\n",
    "batch_size=32\n",
    "\n",
    "for idx,df in enumerate(pub_df_list):\n",
    "    \n",
    "    print('Evaluating:', publist[idx])\n",
    "    y_test = np.array([[0,1]]*100)\n",
    "    X_af3_test, X_sent_test, X_pos_test = process_test_df(df, af3=True, sent=True, pos=True)\n",
    "    \n",
    "    score, acc, f1 = loaded_model3.evaluate([X_sent_test, X_pos_test, X_af3_test], y_test, batch_size=batch_size)\n",
    "    print('Test score:', score)\n",
    "    print('Test accuracy:', acc)\n",
    "    print('Test f1 score:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92bfb06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: guardian\n",
      "4/4 [==============================] - 2s 391ms/step - loss: 0.7749 - accuracy: 0.7100 - f1_m: 0.7685\n",
      "Test score: 0.7748724222183228\n",
      "Test accuracy: 0.7099999785423279\n",
      "Test f1 score: 0.7684771418571472\n",
      "Evaluating: foxnews\n",
      "4/4 [==============================] - 2s 381ms/step - loss: 1.1031 - accuracy: 0.6500 - f1_m: 0.5589\n",
      "Test score: 1.103096842765808\n",
      "Test accuracy: 0.6499999761581421\n",
      "Test f1 score: 0.5588811635971069\n",
      "Evaluating: aljazeera\n",
      "4/4 [==============================] - 2s 491ms/step - loss: 0.9227 - accuracy: 0.6200 - f1_m: 0.5998\n",
      "Test score: 0.9227482080459595\n",
      "Test accuracy: 0.6200000047683716\n",
      "Test f1 score: 0.599759578704834\n"
     ]
    }
   ],
   "source": [
    "# cross-publishers\n",
    "batch_size=32\n",
    "\n",
    "for idx,df in enumerate(pub_df_list):\n",
    "    \n",
    "    print('Evaluating:', publist[idx])\n",
    "    y_test = np.array([[0,1]]*100)\n",
    "    X_af6_test, X_sent_test, X_pos_test = process_test_df(df, af6=True, sent=True, pos=True)\n",
    "    \n",
    "    score, acc, f1 = loaded_model6.evaluate([X_sent_test, X_pos_test, X_af6_test], y_test, batch_size=batch_size)\n",
    "    print('Test score:', score)\n",
    "    print('Test accuracy:', acc)\n",
    "    print('Test f1 score:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b856e7bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
