{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Description***\n",
    "\n",
    "This notebook shows the pre-processing steps of NYTAC corpus, which were previously extracted into .csv file. The processing steps include filtering 'Types of Material' (ed, op-ed, none (a.k.a. news)) and 'Word Count' (> 50 words), and remove mentions of news piece which often appeared in ed and op-ed articles. Then, each article is assigned to a topic depending on keyword in *key_dict* in *filter_col*. If an article has more than one keyword from different topic, I assigned it to the topic belonged to the keyword that appears first. Last, I report the number and ratio of news and editorial articles in each topic, and save everything as .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/users/rldall/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter, OrderedDict\n",
    "from operator import itemgetter\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stops = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set-up\n",
    "# specify required fields\n",
    "fields = ['Body', 'Descriptors', 'General Online Descriptors', 'Lead Paragraph',\n",
    "          'News Desk', 'Online Section', 'Types Of Material','Word Count']\n",
    "\n",
    "# interested materials\n",
    "material_list = ['editorial','op-ed','letter', 'none']\n",
    "\n",
    "# filter for interested topics\n",
    "key_dict = {\n",
    "    'law' : ['law','right','court'],\n",
    "    'politics' : ['politics','relation','international','regional'],\n",
    "    'medicine' : ['medicine','health','disease'],\n",
    "    'finance' : ['finances','business'],\n",
    "    'military' : ['defense','armament','military'],\n",
    "    'education' : ['education','school','teacher']\n",
    "}\n",
    "\n",
    "# select lists of keywords\n",
    "l = [key_dict.get(k) for k in list(key_dict)]\n",
    "flatten_l = [item for sublist in l for item in sublist]\n",
    "\n",
    "# column used for filtering\n",
    "filter_col = 'Descriptors'\n",
    "s = '|'.join([item for item in flatten_l])\n",
    "\n",
    "# import data\n",
    "# train and val data\n",
    "df1 = pd.read_csv('/data/RAW/nyt1996.csv',encoding='latin-1',usecols=fields)\n",
    "df2 = pd.read_csv('/data/RAW/nyt2005.csv',encoding='latin-1',usecols=fields)\n",
    "train_df = pd.concat([df1,df2])\n",
    "\n",
    "# test data\n",
    "test_df = pd.read_csv('/data/RAW/nyt1986.csv',encoding='latin-1',usecols=fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for cleaning dataframes\n",
    "def filter_explore(raw):\n",
    "    print('Current no. rows:', len(raw))\n",
    "    # delete the Lead Paragraph from the Body \n",
    "    raw['Body'] = raw.apply(lambda row : str(row['Body']).replace(str(row['Lead Paragraph']), ''), axis=1)\n",
    "    # selecting columns\n",
    "    filtered_df = raw[['Body', 'Descriptors', 'General Online Descriptors'#, 'News Desk', 'Online Section'\n",
    "                      ,'Types Of Material','Word Count']]\n",
    "    filtered_df = filtered_df.drop_duplicates(subset=['Body'])\n",
    "    # filter Word Count\n",
    "    filtered_df = filtered_df[filtered_df['Word Count'] > 50]\n",
    "    # fill NaN value with 'None'\n",
    "    filtered_df = filtered_df.fillna('None')\n",
    "    # filter Types Of Material\n",
    "    filtered_df['Types Of Material'] = filtered_df['Types Of Material'].str.lower()\n",
    "    filtered_df = filtered_df[filtered_df['Types Of Material'].isin(material_list)]\n",
    "    print('\\nFiltered Material: done')\n",
    "    print('\\ncurrent no. rows:', len(filtered_df))\n",
    "    print('\\nExploring Types of Material')\n",
    "    # exploring types of materials\n",
    "    for m in material_list:\n",
    "        temp = filtered_df[filtered_df['Types Of Material']==m].sort_values('Body')\n",
    "        print('For {}, there are {} articles in total. {} articles lack Descriptors. {} articles lack General Online Descriptors.\\\n",
    "              {} articles does not have any descriptors at all.'.format(\\\n",
    "            m, len(temp), \n",
    "            len(temp[temp['Descriptors']=='None']), len(temp[temp['General Online Descriptors']=='None']),\n",
    "            len(temp[(temp['Descriptors']=='None') & (temp['General Online Descriptors']=='None')]))\n",
    "             )\n",
    "    ### many editorials lack topic labels\n",
    "    return filtered_df\n",
    "\n",
    "# Helper function for filtering keywords\n",
    "def filter_clean(filtered_df, filter_col, s):\n",
    "    filtered_df[filter_col] = filtered_df[filter_col].str.lower()\n",
    "    filtered_topics = filtered_df[filtered_df[filter_col].str.contains(s)==True]\n",
    "    for row in filtered_topics.iterrows():\n",
    "        body = row[1]['Body'].lstrip()\n",
    "        get = re.findall(\"\\([^\\(]*\\.\\s\\d{2}\\)\", body)\n",
    "        if get:        \n",
    "            body = re.sub(\"\\([^\\(]*\\.\\s\\d{2}\\)\",'', body)\n",
    "        body_after = re.sub('To the Editor:','', body)    \n",
    "        filtered_topics._set_value(row[0],'Body',body_after)\n",
    "    print('\\nFiltered Topics: done')\n",
    "    print('\\nCurrent no. rows:', len(filtered_topics))\n",
    "    # split Descriptors into list\n",
    "    filtered_topics['Descriptors'] = filtered_topics['Descriptors'].str.split('|')\n",
    "    filtered_topics['General Online Descriptors'] = filtered_topics['General Online Descriptors'].str.split('|')\n",
    "    return filtered_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to assign topic to the articles\n",
    "\n",
    "# define the main topic by the keyword in descriptors and add Topic column\n",
    "def match_string(list_string,search_string):\n",
    "    result = [re.search(i, search_string).group() for i in list_string if re.search(i, search_string) is not None]\n",
    "    if len(result) > 0:\n",
    "        return result[0]\n",
    "    \n",
    "def match_key(dictionary, search_string):\n",
    "    match_list = [key for key,val in dictionary.items() if any(search_string in s for s in val)]\n",
    "    if len(match_list) > 0:\n",
    "        return match_list[0]\n",
    "\n",
    "def match_topic(df, key_dict):\n",
    "    # add empty column to df\n",
    "    df.insert(0,\"Topic\", \"None\")\n",
    "    for row in df.iterrows():\n",
    "        topic = ''                \n",
    "        if row[1]['Topic'] in list(key_dict):\n",
    "            pass\n",
    "        else:\n",
    "            for des in row[1]['Descriptors']:\n",
    "                match_res = match_string(flatten_l,des)\n",
    "                if match_res:\n",
    "                    topic = match_key(key_dict,match_res)\n",
    "                    if topic:\n",
    "                        df._set_value(row[0],'Topic', topic)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for count and save\n",
    "\n",
    "def count_result(df):\n",
    "    # at some point have to change Types of Material to 'news' and 'editorials'\n",
    "    df.loc[df[\"Types Of Material\"] == 'letter', \"Types Of Material\"] = 'editorial'\n",
    "    df.loc[df[\"Types Of Material\"] == 'op-ed', \"Types Of Material\"] = 'editorial'\n",
    "    df.loc[df[\"Types Of Material\"] == 'none', \"Types Of Material\"] = 'news'\n",
    "    count_df = df.groupby([\"Topic\", \"Types Of Material\"]).size().reset_index(name=\"Count\")\n",
    "    count_df = count_df.pivot('Topic','Types Of Material','Count').reset_index()\n",
    "    count_df['ratio'] = count_df['editorial']/(count_df['editorial']+count_df['news'])\n",
    "    for row in count_df.iterrows():\n",
    "        print ('On the topic {}, we have {} news articles and {} editorials, or {} % editorial'\\\n",
    "               .format(row[1]['Topic'], row[1]['news'], row[1]['editorial'], round(row[1]['ratio'],4)*100))\n",
    "\n",
    "def save_topic_csv(df, data_type, key_dict):\n",
    "    df = df[['Topic','Types Of Material','Body']]\n",
    "    for k in list(key_dict):\n",
    "        save = df[df['Topic']==k]\n",
    "        save[['Types Of Material','Body']].to_csv('/data/ProcessedNYT/'+data_type+'_'+str(k)+'.txt',\n",
    "                                                  sep='\\t', header=False, index=False)\n",
    "        print ('saved topic_txt:', k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_func(input_df, data_type):\n",
    "\n",
    "    # cleaning\n",
    "    filtered_df = filter_explore(input_df)\n",
    "    filtered_topics = filter_clean(filtered_df, filter_col, s)\n",
    "\n",
    "    #assign topic\n",
    "    return_df = match_topic(filtered_topics, key_dict)\n",
    "\n",
    "    # once again drop duplicated bodies\n",
    "    return_df = return_df.drop_duplicates(subset='Body')\n",
    "    print('Remove Duplicates: done')\n",
    "\n",
    "    # check dataset size\n",
    "    print('\\nCurrent no. rows:',len(return_df))\n",
    "    print('Topics size:\\n{}'.format(return_df['Topic'].value_counts()))\n",
    "\n",
    "    # count stat\n",
    "    print('\\nData Summary:')\n",
    "    count_result(return_df)\n",
    "    \n",
    "    # save .txt\n",
    "    save_topic_csv(return_df,data_type, key_dict)\n",
    "    \n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current no. rows: 169081\n",
      "\n",
      "Filtered Material: done\n",
      "\n",
      "current no. rows: 106286\n",
      "\n",
      "Exploring Types of Material\n",
      "For editorial, there are 2801 articles in total. 578 articles lack Descriptors. 209 articles lack General Online Descriptors.              171 articles does not have any descriptors at all.\n",
      "For op-ed, there are 2601 articles in total. 626 articles lack Descriptors. 222 articles lack General Online Descriptors.              212 articles does not have any descriptors at all.\n",
      "For letter, there are 12418 articles in total. 4845 articles lack Descriptors. 4866 articles lack General Online Descriptors.              4839 articles does not have any descriptors at all.\n",
      "For none, there are 88466 articles in total. 24116 articles lack Descriptors. 8700 articles lack General Online Descriptors.              7780 articles does not have any descriptors at all.\n",
      "\n",
      "Filtered Topics: done\n",
      "\n",
      "Current no. rows: 17538\n",
      "Remove Duplicates: done\n",
      "\n",
      "Current no. rows: 16678\n",
      "Topics size:\n",
      "politics     5883\n",
      "law          3136\n",
      "finance      2784\n",
      "education    1692\n",
      "military     1635\n",
      "medicine     1548\n",
      "Name: Topic, dtype: int64\n",
      "\n",
      "Data Summary:\n",
      "On the topic education, we have 1213 news articles and 479 editorials, or 28.310000000000002 % editorial\n",
      "On the topic finance, we have 2277 news articles and 507 editorials, or 18.21 % editorial\n",
      "On the topic law, we have 2281 news articles and 855 editorials, or 27.26 % editorial\n",
      "On the topic medicine, we have 1124 news articles and 424 editorials, or 27.389999999999997 % editorial\n",
      "On the topic military, we have 1256 news articles and 379 editorials, or 23.18 % editorial\n",
      "On the topic politics, we have 4500 news articles and 1383 editorials, or 23.51 % editorial\n",
      "saved topic_txt: law\n",
      "saved topic_txt: politics\n",
      "saved topic_txt: medicine\n",
      "saved topic_txt: finance\n",
      "saved topic_txt: military\n",
      "saved topic_txt: education\n"
     ]
    }
   ],
   "source": [
    "clean_train_df = main_func(train_df, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current no. rows: 26128\n",
      "\n",
      "Filtered Material: done\n",
      "\n",
      "current no. rows: 17549\n",
      "\n",
      "Exploring Types of Material\n",
      "For editorial, there are 370 articles in total. 3 articles lack Descriptors. 18 articles lack General Online Descriptors.              3 articles does not have any descriptors at all.\n",
      "For op-ed, there are 221 articles in total. 12 articles lack Descriptors. 12 articles lack General Online Descriptors.              12 articles does not have any descriptors at all.\n",
      "For letter, there are 1247 articles in total. 71 articles lack Descriptors. 102 articles lack General Online Descriptors.              71 articles does not have any descriptors at all.\n",
      "For none, there are 15711 articles in total. 356 articles lack Descriptors. 857 articles lack General Online Descriptors.              356 articles does not have any descriptors at all.\n",
      "\n",
      "Filtered Topics: done\n",
      "\n",
      "Current no. rows: 3700\n",
      "Remove Duplicates: done\n",
      "\n",
      "Current no. rows: 3700\n",
      "Topics size:\n",
      "politics     1374\n",
      "law           610\n",
      "military      605\n",
      "finance       511\n",
      "medicine      303\n",
      "education     297\n",
      "Name: Topic, dtype: int64\n",
      "\n",
      "Data Summary:\n",
      "On the topic education, we have 243 news articles and 54 editorials, or 18.18 % editorial\n",
      "On the topic finance, we have 447 news articles and 64 editorials, or 12.520000000000001 % editorial\n",
      "On the topic law, we have 480 news articles and 130 editorials, or 21.310000000000002 % editorial\n",
      "On the topic medicine, we have 244 news articles and 59 editorials, or 19.470000000000002 % editorial\n",
      "On the topic military, we have 544 news articles and 61 editorials, or 10.08 % editorial\n",
      "On the topic politics, we have 1166 news articles and 208 editorials, or 15.14 % editorial\n",
      "saved topic_txt: law\n",
      "saved topic_txt: politics\n",
      "saved topic_txt: medicine\n",
      "saved topic_txt: finance\n",
      "saved topic_txt: military\n",
      "saved topic_txt: education\n"
     ]
    }
   ],
   "source": [
    "clean_test_df = main_func(test_df, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current no. rows: 195209\n",
      "\n",
      "Filtered Material: done\n",
      "\n",
      "current no. rows: 123835\n",
      "\n",
      "Exploring Types of Material\n",
      "For editorial, there are 3171 articles in total. 581 articles lack Descriptors. 227 articles lack General Online Descriptors.              174 articles does not have any descriptors at all.\n",
      "For op-ed, there are 2822 articles in total. 638 articles lack Descriptors. 234 articles lack General Online Descriptors.              224 articles does not have any descriptors at all.\n",
      "For letter, there are 13665 articles in total. 4916 articles lack Descriptors. 4968 articles lack General Online Descriptors.              4910 articles does not have any descriptors at all.\n",
      "For none, there are 104177 articles in total. 24472 articles lack Descriptors. 9557 articles lack General Online Descriptors.              8136 articles does not have any descriptors at all.\n",
      "\n",
      "Filtered Topics: done\n",
      "\n",
      "Current no. rows: 21238\n",
      "Remove Duplicates: done\n",
      "\n",
      "Current no. rows: 19623\n",
      "Topics size:\n",
      "politics     7009\n",
      "law          3588\n",
      "finance      3151\n",
      "military     2181\n",
      "education    1908\n",
      "medicine     1786\n",
      "Name: Topic, dtype: int64\n",
      "\n",
      "Data Summary:\n",
      "On the topic education, we have 1392 news articles and 516 editorials, or 27.04 % editorial\n",
      "On the topic finance, we have 2595 news articles and 556 editorials, or 17.65 % editorial\n",
      "On the topic law, we have 2638 news articles and 950 editorials, or 26.479999999999997 % editorial\n",
      "On the topic medicine, we have 1316 news articles and 470 editorials, or 26.32 % editorial\n",
      "On the topic military, we have 1741 news articles and 440 editorials, or 20.169999999999998 % editorial\n",
      "On the topic politics, we have 5448 news articles and 1561 editorials, or 22.27 % editorial\n",
      "saved topic_txt: law\n",
      "saved topic_txt: politics\n",
      "saved topic_txt: medicine\n",
      "saved topic_txt: finance\n",
      "saved topic_txt: military\n",
      "saved topic_txt: education\n"
     ]
    }
   ],
   "source": [
    "clean_all_df = main_func(pd.concat([train_df,test_df]), 'all')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
