{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22dc8b64",
   "metadata": {},
   "source": [
    "***Description***\n",
    "\n",
    "<div> This notebook displays the training of different combined-feature model for the main task (subjectivity classification).\n",
    "<div> In the first part, I listed all the libraries, customized functions, helper functions, etc.\n",
    "<div>Then, I imported data, namely, the training data ('train_finance' - or NYTAC data on the topic of finance in the years 1996 and 2005), and testing data ('test' - or NYTAC data on 6 different topics (including 'finance') in the first three months of the year 1986). This would shade lights on whether each feature could help the model generalize cross-genres and over time.\n",
    "<div> The features trained on are: 3 argumentation feautures (ArgFeat3, originally designed by Alhindi et al. 2020), 6 argumentation features (ArgFeat6), ternary sentence-level sentiment (SentSum), sentence-level POS counts (POSCount). The combination of the features are: ArgFeat3+SentSum, ArgFeat3+POSCount, ArgFeat6+SentSum, ArgFeat6+POSCount, SentSum+ POSCount, ArgFeat3+SentSum+POSCount, and ArgFeat6+SentSum+POSCount."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c42ea75",
   "metadata": {},
   "source": [
    "https://pyimagesearch.com/2019/02/04/keras-multiple-inputs-and-mixed-data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec4f0729",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/users/rldall/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package tagsets to\n",
      "[nltk_data]     /home/users/rldall/nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# All packages\n",
    "from ast import literal_eval\n",
    "from collections import Counter\n",
    "import glob, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "# keras\n",
    "import keras\n",
    "from keras import Input, Model\n",
    "from keras import backend as K\n",
    "from keras.constraints import maxnorm\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional, Concatenate, Embedding, Dense, Dropout, InputLayer, Reshape, SimpleRNN, BatchNormalization, TimeDistributed, Lambda, Activation, MaxPooling1D\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import np_utils\n",
    "# NLTK\n",
    "import nltk\n",
    "from nltk.data import load\n",
    "from nltk import word_tokenize\n",
    "from nltk import StanfordTagger\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('tagsets')\n",
    "tagdict = load('help/tagsets/upenn_tagset.pickle')\n",
    "# torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import transformers\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32515c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set val_set\n",
    "val_ratio = 0.2\n",
    "seed = 32\n",
    "maxlen = 100\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e03cf80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize POS label encoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(list(tagdict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7db9f677",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5684d41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for POS tagging task\n",
    "# POS count\n",
    "def counter_pos(article):\n",
    "    a =[]  \n",
    "    for idx,sent_pos in enumerate(article):\n",
    "        count_pos = Counter(sent_pos)\n",
    "        a.append(dict(count_pos))\n",
    "    return a\n",
    "        \n",
    "def pos_count_article(counter_result, pos_index):\n",
    "    article_pos_count_array = np.zeros(shape=(maxlen,len(le.classes_)))\n",
    "    for art_i,sent_pos_count in enumerate(counter_result):\n",
    "        if art_i >= maxlen:        \n",
    "            pass\n",
    "        else:\n",
    "            for pos_item in sent_pos_count:\n",
    "                try:\n",
    "                    item_idx = pos_index.index(pos_item)\n",
    "                    article_pos_count_array[art_i,item_idx] = sent_pos_count.get(pos_item)\n",
    "                except:\n",
    "                    pass\n",
    "    return article_pos_count_array\n",
    "\n",
    "# Helper function for padding\n",
    "def padding_X(X):    \n",
    "    return sequence.pad_sequences(X, maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28e2d90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to transform test data\n",
    "def process_test_df(df,af3=False,af6=False,sent=False,pos=False):\n",
    "    \n",
    "    out = []\n",
    "\n",
    "    # labels\n",
    "    labels = df[label_col].values\n",
    "    labels = pd.get_dummies(labels).to_numpy()\n",
    "    out.append(labels)\n",
    "\n",
    "    # argfeat\n",
    "    if af3:\n",
    "        x_argfeat3 = df[argfeat3_col].apply(literal_eval)\n",
    "        X_argfeat3 = padding_X(x_argfeat3)\n",
    "        out.append(X_argfeat3)\n",
    "    \n",
    "    if af6:\n",
    "        x_argfeat6 = df[argfeat6_col].apply(literal_eval)\n",
    "        X_argfeat6 = padding_X(x_argfeat6)\n",
    "        out.append(X_argfeat6)\n",
    "\n",
    "    # sent_sum\n",
    "    if sent:\n",
    "        x_sent = df[sentsum_col].apply(literal_eval)\n",
    "        X_sent = padding_X(x_sent)\n",
    "        out.append(X_sent)\n",
    "\n",
    "    # pos count\n",
    "    if pos:        \n",
    "        x_pos = df[pos_col].apply(literal_eval)\n",
    "        x_pos_list = [] \n",
    "        for x in x_pos: \n",
    "            art_pos = pos_count_article(counter_pos(x_pos[0]),list(le.classes_)).reshape(-1,1)\n",
    "            x_pos_list.append(art_pos) \n",
    "        X_pos = np.stack(x_pos_list) \n",
    "        X_pos = X_pos.reshape(X_pos.shape[0],X_pos.shape[1]) \n",
    "        out.append(X_pos)\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edd4fc6",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41ab468e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_files(path, startwith):\n",
    "    list_of_files = []\n",
    "    files = os.listdir(path)\n",
    "    for file in files:\n",
    "        if file.startswith(startwith):\n",
    "            list_of_files.append(str(path)+str(file))\n",
    "    return list_of_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cfed985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: /data/ProcessedNYT/train_finance.txt\n"
     ]
    }
   ],
   "source": [
    "# use train_finance as the train data\n",
    "list_of_train_files = select_files('/data/ProcessedNYT/','train')\n",
    "train_df = pd.read_csv(list_of_train_files[2], sep='\\t', header=None)\n",
    "print ('Training data:', list_of_train_files[2])\n",
    "\n",
    "# use 1986 data as test data\n",
    "list_of_files = select_files('/data/ProcessedNYT/','test')\n",
    "list_of_dfs = [pd.read_csv(file, sep='\\t', header=None) for file in list_of_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56d82a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: /data/ProcessedNYT/all_finance.txt\n"
     ]
    }
   ],
   "source": [
    "# use all_finance as the train data\n",
    "list_of_files = select_files('/data/ProcessedNYT/','all')\n",
    "train_df = pd.read_csv(list_of_files[2], sep='\\t', header=None)\n",
    "print ('Training data:', list_of_files[2])\n",
    "\n",
    "# use 1986 data as test data\n",
    "list_of_dfs = [pd.read_csv(file, sep='\\t', header=None) for file in list_of_files]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103b963d",
   "metadata": {},
   "source": [
    "# Transform training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a24fdc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column definition\n",
    "label_col = 0\n",
    "argfeat3_col = 6\n",
    "argfeat6_col = 7\n",
    "sentsum_col = 4\n",
    "pos_col = 5\n",
    "\n",
    "# labels\n",
    "labels = train_df[label_col].values\n",
    "labels = pd.get_dummies(labels).to_numpy()\n",
    "\n",
    "# argfeat\n",
    "x_argfeat3 = train_df[argfeat3_col].apply(literal_eval)\n",
    "X_argfeat3 = padding_X(x_argfeat3)\n",
    "x_argfeat6 = train_df[argfeat6_col].apply(literal_eval)\n",
    "X_argfeat6 = padding_X(x_argfeat6)\n",
    "\n",
    "# sent_sum\n",
    "x_sent = train_df[sentsum_col].apply(literal_eval)\n",
    "X_sent = padding_X(x_sent)\n",
    "\n",
    "# raw_pos\n",
    "x_pos = train_df[pos_col].apply(literal_eval)\n",
    "x_pos_list = []\n",
    "for x in x_pos: \n",
    "    art_pos = pos_count_article(counter_pos(x_pos[0]),list(le.classes_)).reshape(-1,1)\n",
    "    x_pos_list.append(art_pos) \n",
    "X_pos = np.stack(x_pos_list) \n",
    "X_pos = X_pos.reshape(X_pos.shape[0],X_pos.shape[1]) \n",
    "\n",
    "# split data\n",
    "y_train, y_val = train_test_split(labels, test_size=val_ratio, random_state=seed)\n",
    "X_af3_train, X_af3_val = train_test_split(X_argfeat3, test_size=val_ratio, random_state=seed)\n",
    "X_af6_train, X_af6_val = train_test_split(X_argfeat6, test_size=val_ratio, random_state=seed)\n",
    "X_sent_train, X_sent_val = train_test_split(X_sent, test_size=val_ratio, random_state=seed)\n",
    "X_pos_train, X_pos_val = train_test_split(X_pos, test_size=val_ratio, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267eab7d",
   "metadata": {},
   "source": [
    "# Model Combination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffbe6ae",
   "metadata": {},
   "source": [
    "## Combined model: argfeat3 + sent_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfba9ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 100, 128)     384         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 100, 128)     384         ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " simple_rnn (SimpleRNN)         (None, 128)          32896       ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " simple_rnn_1 (SimpleRNN)       (None, 128)          32896       ['embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 256)          0           ['simple_rnn[0][0]',             \n",
      "                                                                  'simple_rnn_1[0][0]']           \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 2)            514         ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 67,074\n",
      "Trainable params: 67,074\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-09 19:51:02.571818: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-09 19:51:03.331216: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10413 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:84:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "input_sent = Input(shape=(X_sent.shape[1],))\n",
    "model_sent = Embedding(3, 128)(input_sent)\n",
    "model_sent = SimpleRNN(128, dropout=0.2)(model_sent)\n",
    "\n",
    "input_af3 = Input(shape=(X_argfeat3.shape[1],))\n",
    "model_af3 = Embedding(3, 128)(input_af3)\n",
    "model_af3 = SimpleRNN(128, dropout=0.2)(model_af3)\n",
    "\n",
    "merged = Concatenate()([model_sent, model_af3])\n",
    "dense_pred = (Dense(2, activation='sigmoid'))(merged)\n",
    "\n",
    "model = Model(inputs=[input_sent, input_af3], outputs=dense_pred)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',f1_m])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6484e79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "70/70 [==============================] - 15s 173ms/step - loss: 0.3979 - accuracy: 0.8284 - f1_m: 0.8278 - val_loss: 0.3867 - val_accuracy: 0.8241 - val_f1_m: 0.8274\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 12s 173ms/step - loss: 0.3836 - accuracy: 0.8419 - f1_m: 0.8421 - val_loss: 0.2472 - val_accuracy: 0.8995 - val_f1_m: 0.9022\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 12s 177ms/step - loss: 0.2629 - accuracy: 0.8980 - f1_m: 0.8971 - val_loss: 0.2164 - val_accuracy: 0.9120 - val_f1_m: 0.9166\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 11s 160ms/step - loss: 0.2878 - accuracy: 0.8868 - f1_m: 0.8856 - val_loss: 0.2830 - val_accuracy: 0.8797 - val_f1_m: 0.8790\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 12s 164ms/step - loss: 0.2818 - accuracy: 0.8886 - f1_m: 0.8875 - val_loss: 0.2417 - val_accuracy: 0.8941 - val_f1_m: 0.8990\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "model.fit([X_sent_train,X_af3_train],np.array(y_train),\n",
    "          batch_size=batch_size,\n",
    "          epochs=5,\n",
    "          validation_data=([X_sent_val,X_af3_val],np.array(y_val)))\n",
    "\n",
    "model.save(\"af3_sent.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16acdb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: /data/ProcessedNYT/test_military.txt\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.1798 - accuracy: 0.9455 - f1_m: 0.9467\n",
      "Test score: 0.17975829541683197\n",
      "Test accuracy: 0.9454545378684998\n",
      "Test f1 score: 0.9466598629951477\n",
      "Evaluating: /data/ProcessedNYT/test_law.txt\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.2847 - accuracy: 0.8738 - f1_m: 0.8825\n",
      "Test score: 0.2846507728099823\n",
      "Test accuracy: 0.8737704753875732\n",
      "Test f1 score: 0.8824936151504517\n",
      "Evaluating: /data/ProcessedNYT/test_finance.txt\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.1884 - accuracy: 0.9235 - f1_m: 0.9248\n",
      "Test score: 0.1883891522884369\n",
      "Test accuracy: 0.9235293865203857\n",
      "Test f1 score: 0.9247795343399048\n",
      "Evaluating: /data/ProcessedNYT/test_education.txt\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2314 - accuracy: 0.9088 - f1_m: 0.9048\n",
      "Test score: 0.23138388991355896\n",
      "Test accuracy: 0.9087837934494019\n",
      "Test f1 score: 0.9047595858573914\n",
      "Evaluating: /data/ProcessedNYT/test_politics.txt\n",
      "43/43 [==============================] - 1s 23ms/step - loss: 0.2177 - accuracy: 0.9148 - f1_m: 0.9145\n",
      "Test score: 0.21768297255039215\n",
      "Test accuracy: 0.9148471355438232\n",
      "Test f1 score: 0.9145348072052002\n",
      "Evaluating: /data/ProcessedNYT/test_medicine.txt\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.3026 - accuracy: 0.8647 - f1_m: 0.8662\n",
      "Test score: 0.3025854825973511\n",
      "Test accuracy: 0.8646864891052246\n",
      "Test f1 score: 0.866161048412323\n"
     ]
    }
   ],
   "source": [
    "for idx,df in enumerate(list_of_dfs):\n",
    "    \n",
    "    print('Evaluating:',list_of_files[idx])\n",
    "    y_test, X_af3_test, X_sent_test = process_test_df(df, af3=True, sent=True)\n",
    "    \n",
    "    score, acc, f1 = model.evaluate([X_sent_test,X_af3_test], y_test, batch_size=batch_size)\n",
    "    print('Test score:', score)\n",
    "    print('Test accuracy:', acc)\n",
    "    print('Test f1 score:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ec3a28",
   "metadata": {},
   "source": [
    "## Combined model: argfeat6 + sent_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3f28893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)        (None, 100, 128)     384         ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)        (None, 100, 128)     768         ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " simple_rnn_2 (SimpleRNN)       (None, 128)          32896       ['embedding_2[0][0]']            \n",
      "                                                                                                  \n",
      " simple_rnn_3 (SimpleRNN)       (None, 128)          32896       ['embedding_3[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 256)          0           ['simple_rnn_2[0][0]',           \n",
      "                                                                  'simple_rnn_3[0][0]']           \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 2)            514         ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 67,458\n",
      "Trainable params: 67,458\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_sent = Input(shape=(X_sent.shape[1],))\n",
    "model_sent = Embedding(3, 128)(input_sent)\n",
    "model_sent = SimpleRNN(128, dropout=0.2)(model_sent)\n",
    "\n",
    "input_af6 = Input(shape=(X_argfeat6.shape[1],))\n",
    "model_af6 = Embedding(6, 128)(input_af6)\n",
    "model_af6 = SimpleRNN(128, dropout=0.2)(model_af6)\n",
    "\n",
    "merged = Concatenate()([model_sent, model_af6])\n",
    "dense_pred = (Dense(2, activation='sigmoid'))(merged)\n",
    "\n",
    "model = Model(inputs=[input_sent, input_af6], outputs=dense_pred)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',f1_m])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f60dd60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "70/70 [==============================] - 14s 182ms/step - loss: 0.4325 - accuracy: 0.8176 - f1_m: 0.8187 - val_loss: 0.3297 - val_accuracy: 0.8833 - val_f1_m: 0.8827\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 12s 171ms/step - loss: 0.2942 - accuracy: 0.8819 - f1_m: 0.8817 - val_loss: 0.2574 - val_accuracy: 0.8995 - val_f1_m: 0.9005\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 12s 173ms/step - loss: 0.2637 - accuracy: 0.8940 - f1_m: 0.8929 - val_loss: 0.2220 - val_accuracy: 0.9138 - val_f1_m: 0.9148\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 11s 163ms/step - loss: 0.2562 - accuracy: 0.8962 - f1_m: 0.8982 - val_loss: 0.2833 - val_accuracy: 0.8977 - val_f1_m: 0.8974\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 12s 172ms/step - loss: 0.2634 - accuracy: 0.8971 - f1_m: 0.8982 - val_loss: 0.2173 - val_accuracy: 0.9066 - val_f1_m: 0.9084\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "model.fit([X_sent_train,X_af6_train],np.array(y_train),\n",
    "          batch_size=batch_size,\n",
    "          epochs=5,\n",
    "          validation_data=([X_sent_val,X_af6_val],np.array(y_val)))\n",
    "\n",
    "model.save(\"af6_sent.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c2b1f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: /data/ProcessedNYT/test_military.txt\n",
      "19/19 [==============================] - 0s 22ms/step - loss: 0.1571 - accuracy: 0.9504 - f1_m: 0.9481\n",
      "Test score: 0.15713836252689362\n",
      "Test accuracy: 0.9504132270812988\n",
      "Test f1 score: 0.9480684995651245\n",
      "Evaluating: /data/ProcessedNYT/test_law.txt\n",
      "20/20 [==============================] - 0s 21ms/step - loss: 0.2590 - accuracy: 0.8836 - f1_m: 0.8857\n",
      "Test score: 0.2590218186378479\n",
      "Test accuracy: 0.8836065530776978\n",
      "Test f1 score: 0.8857123255729675\n",
      "Evaluating: /data/ProcessedNYT/test_finance.txt\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.1768 - accuracy: 0.9373 - f1_m: 0.9384\n",
      "Test score: 0.17684735357761383\n",
      "Test accuracy: 0.9372549057006836\n",
      "Test f1 score: 0.938399076461792\n",
      "Evaluating: /data/ProcessedNYT/test_education.txt\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.1764 - accuracy: 0.9392 - f1_m: 0.9438\n",
      "Test score: 0.17644309997558594\n",
      "Test accuracy: 0.9391891956329346\n",
      "Test f1 score: 0.9437500238418579\n",
      "Evaluating: /data/ProcessedNYT/test_politics.txt\n",
      "43/43 [==============================] - 1s 21ms/step - loss: 0.1997 - accuracy: 0.9207 - f1_m: 0.9189\n",
      "Test score: 0.1996869295835495\n",
      "Test accuracy: 0.9206695556640625\n",
      "Test f1 score: 0.918850302696228\n",
      "Evaluating: /data/ProcessedNYT/test_medicine.txt\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.2410 - accuracy: 0.9010 - f1_m: 0.9045\n",
      "Test score: 0.24100108444690704\n",
      "Test accuracy: 0.9009901285171509\n",
      "Test f1 score: 0.9044642448425293\n"
     ]
    }
   ],
   "source": [
    "for idx,df in enumerate(list_of_dfs):\n",
    "    \n",
    "    print('Evaluating:',list_of_files[idx])\n",
    "    y_test, X_af6_test, X_sent_test = process_test_df(df, af6=True, sent=True)\n",
    "    \n",
    "    score, acc, f1 = model.evaluate([X_sent_test,X_af6_test], y_test, batch_size=batch_size)\n",
    "    print('Test score:', score)\n",
    "    print('Test accuracy:', acc)\n",
    "    print('Test f1 score:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae1ee6a",
   "metadata": {},
   "source": [
    "## Combined model: argfeat3 + pos_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0d0d7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 4500)]       0           []                               \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_4 (Embedding)        (None, 4500, 128)    5760        ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_5 (Embedding)        (None, 100, 128)     384         ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " simple_rnn_4 (SimpleRNN)       (None, 128)          32896       ['embedding_4[0][0]']            \n",
      "                                                                                                  \n",
      " simple_rnn_5 (SimpleRNN)       (None, 128)          32896       ['embedding_5[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 256)          0           ['simple_rnn_4[0][0]',           \n",
      "                                                                  'simple_rnn_5[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 2)            514         ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 72,450\n",
      "Trainable params: 72,450\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_pos = Input(shape=(X_pos.shape[1],))\n",
    "model_pos = Embedding(len(le.classes_), 128)(input_pos)\n",
    "model_pos = SimpleRNN(128, dropout=0.2)(model_pos)\n",
    "\n",
    "input_af3 = Input(shape=(X_argfeat3.shape[1],))\n",
    "model_af3 = Embedding(3, 128)(input_af3)\n",
    "model_af3 = SimpleRNN(128, dropout=0.2)(model_af3)\n",
    "\n",
    "merged = Concatenate()([model_pos, model_af3])\n",
    "dense_pred = (Dense(2, activation='sigmoid'))(merged)\n",
    "\n",
    "model = Model(inputs=[input_pos, input_af3], outputs=dense_pred)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',f1_m])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6e67182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "70/70 [==============================] - 418s 6s/step - loss: 0.3897 - accuracy: 0.8401 - f1_m: 0.8377 - val_loss: 0.3831 - val_accuracy: 0.8582 - val_f1_m: 0.8632\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 413s 6s/step - loss: 0.3665 - accuracy: 0.8473 - f1_m: 0.8461 - val_loss: 0.2839 - val_accuracy: 0.8761 - val_f1_m: 0.8713\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 406s 6s/step - loss: 0.3626 - accuracy: 0.8414 - f1_m: 0.8423 - val_loss: 0.3747 - val_accuracy: 0.8366 - val_f1_m: 0.8463\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 420s 6s/step - loss: 0.3457 - accuracy: 0.8486 - f1_m: 0.8507 - val_loss: 0.2661 - val_accuracy: 0.8761 - val_f1_m: 0.8784\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 411s 6s/step - loss: 0.2819 - accuracy: 0.8845 - f1_m: 0.8834 - val_loss: 0.2266 - val_accuracy: 0.8977 - val_f1_m: 0.8995\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "model.fit([X_pos_train,X_af3_train],np.array(y_train),\n",
    "          batch_size=batch_size,\n",
    "          epochs=5,\n",
    "          validation_data=([X_pos_val,X_af3_val],np.array(y_val)))\n",
    "\n",
    "model.save(\"af3_pos.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76519842",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: /data/ProcessedNYT/test_military.txt\n",
      "19/19 [==============================] - 7s 373ms/step - loss: 0.1679 - accuracy: 0.9537 - f1_m: 0.9531\n",
      "Test score: 0.16792236268520355\n",
      "Test accuracy: 0.9537190198898315\n",
      "Test f1 score: 0.9531376361846924\n",
      "Evaluating: /data/ProcessedNYT/test_law.txt\n",
      "20/20 [==============================] - 8s 389ms/step - loss: 0.2734 - accuracy: 0.8869 - f1_m: 0.8925\n",
      "Test score: 0.2733813524246216\n",
      "Test accuracy: 0.8868852257728577\n",
      "Test f1 score: 0.8925479650497437\n",
      "Evaluating: /data/ProcessedNYT/test_finance.txt\n",
      "16/16 [==============================] - 6s 377ms/step - loss: 0.1887 - accuracy: 0.9255 - f1_m: 0.9277\n",
      "Test score: 0.18869280815124512\n",
      "Test accuracy: 0.9254902005195618\n",
      "Test f1 score: 0.9277416467666626\n",
      "Evaluating: /data/ProcessedNYT/test_education.txt\n",
      "10/10 [==============================] - 4s 380ms/step - loss: 0.2324 - accuracy: 0.8953 - f1_m: 0.8899\n",
      "Test score: 0.2323516607284546\n",
      "Test accuracy: 0.8952702879905701\n",
      "Test f1 score: 0.8899038434028625\n",
      "Evaluating: /data/ProcessedNYT/test_politics.txt\n",
      "43/43 [==============================] - 18s 403ms/step - loss: 0.2087 - accuracy: 0.9265 - f1_m: 0.9249\n",
      "Test score: 0.20867164433002472\n",
      "Test accuracy: 0.9264919757843018\n",
      "Test f1 score: 0.9248571395874023\n",
      "Evaluating: /data/ProcessedNYT/test_medicine.txt\n",
      "10/10 [==============================] - 4s 374ms/step - loss: 0.3090 - accuracy: 0.8581 - f1_m: 0.8658\n",
      "Test score: 0.30896636843681335\n",
      "Test accuracy: 0.8580858111381531\n",
      "Test f1 score: 0.8657852411270142\n"
     ]
    }
   ],
   "source": [
    "for idx,df in enumerate(list_of_dfs):\n",
    "    \n",
    "    print('Evaluating:',list_of_files[idx])\n",
    "    y_test, X_af3_test, X_pos_test = process_test_df(df, af3=True, pos=True)\n",
    "    \n",
    "    score, acc, f1 = model.evaluate([X_pos_test,X_af3_test], y_test, batch_size=batch_size)\n",
    "    print('Test score:', score)\n",
    "    print('Test accuracy:', acc)\n",
    "    print('Test f1 score:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b224a0dd",
   "metadata": {},
   "source": [
    "## Combined model: argfeat6 + pos_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eccab40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)           [(None, 4500)]       0           []                               \n",
      "                                                                                                  \n",
      " input_8 (InputLayer)           [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_6 (Embedding)        (None, 4500, 128)    5760        ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_7 (Embedding)        (None, 100, 128)     768         ['input_8[0][0]']                \n",
      "                                                                                                  \n",
      " simple_rnn_6 (SimpleRNN)       (None, 128)          32896       ['embedding_6[0][0]']            \n",
      "                                                                                                  \n",
      " simple_rnn_7 (SimpleRNN)       (None, 128)          32896       ['embedding_7[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 256)          0           ['simple_rnn_6[0][0]',           \n",
      "                                                                  'simple_rnn_7[0][0]']           \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 2)            514         ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 72,834\n",
      "Trainable params: 72,834\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_pos = Input(shape=(X_pos.shape[1],))\n",
    "model_pos = Embedding(len(le.classes_), 128)(input_pos)\n",
    "model_pos = SimpleRNN(128, dropout=0.2)(model_pos)\n",
    "\n",
    "input_af6 = Input(shape=(X_argfeat6.shape[1],))\n",
    "model_af6 = Embedding(6, 128)(input_af6)\n",
    "model_af6 = SimpleRNN(128, dropout=0.2)(model_af6)\n",
    "\n",
    "merged = Concatenate()([model_pos, model_af6])\n",
    "dense_pred = (Dense(2, activation='sigmoid'))(merged)\n",
    "\n",
    "model = Model(inputs=[input_pos, input_af6], outputs=dense_pred)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',f1_m])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3fb7326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "70/70 [==============================] - 399s 6s/step - loss: 0.4023 - accuracy: 0.8351 - f1_m: 0.8340 - val_loss: 0.2658 - val_accuracy: 0.8779 - val_f1_m: 0.8776\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 401s 6s/step - loss: 0.2994 - accuracy: 0.8769 - f1_m: 0.8749 - val_loss: 0.2323 - val_accuracy: 0.8941 - val_f1_m: 0.8947\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 404s 6s/step - loss: 0.2674 - accuracy: 0.8949 - f1_m: 0.8942 - val_loss: 0.3869 - val_accuracy: 0.8241 - val_f1_m: 0.8262\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 401s 6s/step - loss: 0.2934 - accuracy: 0.8747 - f1_m: 0.8753 - val_loss: 0.3053 - val_accuracy: 0.8618 - val_f1_m: 0.8604\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 408s 6s/step - loss: 0.3549 - accuracy: 0.8347 - f1_m: 0.8333 - val_loss: 0.2868 - val_accuracy: 0.8707 - val_f1_m: 0.8748\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "model.fit([X_pos_train,X_af6_train],np.array(y_train),\n",
    "          batch_size=batch_size,\n",
    "          epochs=5,\n",
    "          validation_data=([X_pos_val,X_af6_val],np.array(y_val)))\n",
    "\n",
    "model.save(\"af6_pos.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7407c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: /data/ProcessedNYT/test_military.txt\n",
      "19/19 [==============================] - 7s 376ms/step - loss: 0.1570 - accuracy: 0.9488 - f1_m: 0.9476\n",
      "Test score: 0.15697097778320312\n",
      "Test accuracy: 0.9487603306770325\n",
      "Test f1 score: 0.9475938081741333\n",
      "Evaluating: /data/ProcessedNYT/test_law.txt\n",
      "20/20 [==============================] - 8s 398ms/step - loss: 0.3074 - accuracy: 0.8525 - f1_m: 0.8599\n",
      "Test score: 0.3073975741863251\n",
      "Test accuracy: 0.8524590134620667\n",
      "Test f1 score: 0.8598685264587402\n",
      "Evaluating: /data/ProcessedNYT/test_finance.txt\n",
      "16/16 [==============================] - 6s 400ms/step - loss: 0.2264 - accuracy: 0.8922 - f1_m: 0.8949\n",
      "Test score: 0.22637878358364105\n",
      "Test accuracy: 0.8921568393707275\n",
      "Test f1 score: 0.8948733806610107\n",
      "Evaluating: /data/ProcessedNYT/test_education.txt\n",
      "10/10 [==============================] - 4s 372ms/step - loss: 0.2708 - accuracy: 0.8784 - f1_m: 0.8764\n",
      "Test score: 0.270818293094635\n",
      "Test accuracy: 0.8783783912658691\n",
      "Test f1 score: 0.8763877153396606\n",
      "Evaluating: /data/ProcessedNYT/test_politics.txt\n",
      "43/43 [==============================] - 17s 393ms/step - loss: 0.2159 - accuracy: 0.9090 - f1_m: 0.9100\n",
      "Test score: 0.21589882671833038\n",
      "Test accuracy: 0.9090247750282288\n",
      "Test f1 score: 0.9099516868591309\n",
      "Evaluating: /data/ProcessedNYT/test_medicine.txt\n",
      "10/10 [==============================] - 4s 374ms/step - loss: 0.3293 - accuracy: 0.8581 - f1_m: 0.8696\n",
      "Test score: 0.32931947708129883\n",
      "Test accuracy: 0.8580858111381531\n",
      "Test f1 score: 0.8696168065071106\n"
     ]
    }
   ],
   "source": [
    "for idx,df in enumerate(list_of_dfs):\n",
    "    \n",
    "    print('Evaluating:',list_of_files[idx])\n",
    "    y_test, X_af6_test, X_pos_test = process_test_df(df, af6=True, pos=True)\n",
    "    \n",
    "    score, acc, f1 = model.evaluate([X_pos_test,X_af6_test], y_test, batch_size=batch_size)\n",
    "    print('Test score:', score)\n",
    "    print('Test accuracy:', acc)\n",
    "    print('Test f1 score:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c34941",
   "metadata": {},
   "source": [
    "## Combined model: sent_sum + pos_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b4b0ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)           [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " input_10 (InputLayer)          [(None, 4500)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_8 (Embedding)        (None, 100, 128)     384         ['input_9[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_9 (Embedding)        (None, 4500, 128)    5760        ['input_10[0][0]']               \n",
      "                                                                                                  \n",
      " simple_rnn_8 (SimpleRNN)       (None, 128)          32896       ['embedding_8[0][0]']            \n",
      "                                                                                                  \n",
      " simple_rnn_9 (SimpleRNN)       (None, 128)          32896       ['embedding_9[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 256)          0           ['simple_rnn_8[0][0]',           \n",
      "                                                                  'simple_rnn_9[0][0]']           \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 2)            514         ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 72,450\n",
      "Trainable params: 72,450\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_sent = Input(shape=(X_sent.shape[1],))\n",
    "model_sent = Embedding(3, 128)(input_sent)\n",
    "model_sent = SimpleRNN(128, dropout=0.2)(model_sent)\n",
    "\n",
    "input_pos = Input(shape=(X_pos.shape[1],))\n",
    "model_pos = Embedding(len(le.classes_), 128)(input_pos)\n",
    "model_pos = SimpleRNN(128, dropout=0.2)(model_pos)\n",
    "\n",
    "merged = Concatenate()([model_sent, model_pos])\n",
    "dense_pred = (Dense(2, activation='sigmoid'))(merged)\n",
    "\n",
    "model = Model(inputs=[input_sent, input_pos], outputs=dense_pred)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',f1_m])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27b2d374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "70/70 [==============================] - 400s 6s/step - loss: 0.4872 - accuracy: 0.8091 - f1_m: 0.8067 - val_loss: 0.4478 - val_accuracy: 0.8312 - val_f1_m: 0.8317\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 396s 6s/step - loss: 0.4743 - accuracy: 0.8145 - f1_m: 0.8132 - val_loss: 0.4431 - val_accuracy: 0.8312 - val_f1_m: 0.8317\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 398s 6s/step - loss: 0.4696 - accuracy: 0.8145 - f1_m: 0.8142 - val_loss: 0.4528 - val_accuracy: 0.8312 - val_f1_m: 0.8317\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 401s 6s/step - loss: 0.4706 - accuracy: 0.8086 - f1_m: 0.8100 - val_loss: 0.4444 - val_accuracy: 0.8312 - val_f1_m: 0.8317\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 402s 6s/step - loss: 0.4549 - accuracy: 0.8172 - f1_m: 0.8177 - val_loss: 0.4497 - val_accuracy: 0.8312 - val_f1_m: 0.8317\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "model.fit([X_sent_train, X_pos_train],np.array(y_train),\n",
    "          batch_size=batch_size,\n",
    "          epochs=5,\n",
    "          validation_data=([X_sent_val, X_pos_val],np.array(y_val)))\n",
    "\n",
    "model.save(\"sent_pos.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d15a64d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: /data/ProcessedNYT/test_military.txt\n",
      "19/19 [==============================] - 7s 382ms/step - loss: 0.3323 - accuracy: 0.8992 - f1_m: 0.8993\n",
      "Test score: 0.33232590556144714\n",
      "Test accuracy: 0.8991735577583313\n",
      "Test f1 score: 0.899330735206604\n",
      "Evaluating: /data/ProcessedNYT/test_law.txt\n",
      "20/20 [==============================] - 8s 391ms/step - loss: 0.5373 - accuracy: 0.7869 - f1_m: 0.7969\n",
      "Test score: 0.5373057723045349\n",
      "Test accuracy: 0.7868852615356445\n",
      "Test f1 score: 0.7968749403953552\n",
      "Evaluating: /data/ProcessedNYT/test_finance.txt\n",
      "16/16 [==============================] - 6s 400ms/step - loss: 0.3736 - accuracy: 0.8745 - f1_m: 0.8742\n",
      "Test score: 0.3735803961753845\n",
      "Test accuracy: 0.8745098114013672\n",
      "Test f1 score: 0.8742187023162842\n",
      "Evaluating: /data/ProcessedNYT/test_education.txt\n",
      "10/10 [==============================] - 4s 376ms/step - loss: 0.4781 - accuracy: 0.8176 - f1_m: 0.8125\n",
      "Test score: 0.478145956993103\n",
      "Test accuracy: 0.8175675868988037\n",
      "Test f1 score: 0.8124998807907104\n",
      "Evaluating: /data/ProcessedNYT/test_politics.txt\n",
      "43/43 [==============================] - 16s 377ms/step - loss: 0.4201 - accuracy: 0.8486 - f1_m: 0.8485\n",
      "Test score: 0.4200834333896637\n",
      "Test accuracy: 0.8486171960830688\n",
      "Test f1 score: 0.8485463857650757\n",
      "Evaluating: /data/ProcessedNYT/test_medicine.txt\n",
      "10/10 [==============================] - 4s 403ms/step - loss: 0.5007 - accuracy: 0.8053 - f1_m: 0.8050\n",
      "Test score: 0.5006592869758606\n",
      "Test accuracy: 0.8052805066108704\n",
      "Test f1 score: 0.8049999475479126\n"
     ]
    }
   ],
   "source": [
    "for idx,df in enumerate(list_of_dfs):\n",
    "    \n",
    "    print('Evaluating:',list_of_files[idx])\n",
    "    y_test, X_sent_test, X_pos_test = process_test_df(df, sent = True, pos=True)\n",
    "    \n",
    "    score, acc, f1 = model.evaluate([X_sent_test, X_pos_test], y_test, batch_size=batch_size)\n",
    "    print('Test score:', score)\n",
    "    print('Test accuracy:', acc)\n",
    "    print('Test f1 score:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f08ffb4",
   "metadata": {},
   "source": [
    "## Combined model: argfeat3 + sent_sum + pos_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7cd6895b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_11 (InputLayer)          [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " input_12 (InputLayer)          [(None, 4500)]       0           []                               \n",
      "                                                                                                  \n",
      " input_13 (InputLayer)          [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_10 (Embedding)       (None, 100, 128)     384         ['input_11[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_11 (Embedding)       (None, 4500, 128)    5760        ['input_12[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_12 (Embedding)       (None, 100, 128)     384         ['input_13[0][0]']               \n",
      "                                                                                                  \n",
      " simple_rnn_10 (SimpleRNN)      (None, 128)          32896       ['embedding_10[0][0]']           \n",
      "                                                                                                  \n",
      " simple_rnn_11 (SimpleRNN)      (None, 128)          32896       ['embedding_11[0][0]']           \n",
      "                                                                                                  \n",
      " simple_rnn_12 (SimpleRNN)      (None, 128)          32896       ['embedding_12[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 384)          0           ['simple_rnn_10[0][0]',          \n",
      "                                                                  'simple_rnn_11[0][0]',          \n",
      "                                                                  'simple_rnn_12[0][0]']          \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 2)            770         ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 105,986\n",
      "Trainable params: 105,986\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_sent = Input(shape=(X_sent.shape[1],))\n",
    "model_sent = Embedding(3, 128)(input_sent)\n",
    "model_sent = SimpleRNN(128, dropout=0.2)(model_sent)\n",
    "\n",
    "input_pos = Input(shape=(X_pos.shape[1],))\n",
    "model_pos = Embedding(len(le.classes_), 128)(input_pos)\n",
    "model_pos = SimpleRNN(128, dropout=0.2)(model_pos)\n",
    "\n",
    "input_af3 = Input(shape=(X_argfeat3.shape[1],))\n",
    "model_af3 = Embedding(3, 128)(input_af3)\n",
    "model_af3 = SimpleRNN(128, dropout=0.2)(model_af3)\n",
    "\n",
    "merged = Concatenate()([model_sent, model_pos, model_af3])\n",
    "dense_pred = (Dense(2, activation='sigmoid'))(merged)\n",
    "\n",
    "model = Model(inputs=[input_sent, input_pos, input_af3], outputs=dense_pred)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',f1_m])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ff2915f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "70/70 [==============================] - 404s 6s/step - loss: 0.4459 - accuracy: 0.8127 - f1_m: 0.8116 - val_loss: 0.2845 - val_accuracy: 0.8941 - val_f1_m: 0.9015\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 397s 6s/step - loss: 0.3262 - accuracy: 0.8616 - f1_m: 0.8580 - val_loss: 0.2607 - val_accuracy: 0.8959 - val_f1_m: 0.8922\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 400s 6s/step - loss: 0.3014 - accuracy: 0.8747 - f1_m: 0.8713 - val_loss: 0.2515 - val_accuracy: 0.9120 - val_f1_m: 0.9092\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 404s 6s/step - loss: 0.2635 - accuracy: 0.8971 - f1_m: 0.8980 - val_loss: 0.2139 - val_accuracy: 0.9174 - val_f1_m: 0.9169\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 403s 6s/step - loss: 0.2359 - accuracy: 0.9102 - f1_m: 0.9100 - val_loss: 0.2191 - val_accuracy: 0.9138 - val_f1_m: 0.9168\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "model.fit([X_sent_train, X_pos_train,X_af3_train],np.array(y_train),\n",
    "          batch_size=batch_size,\n",
    "          epochs=5,\n",
    "          validation_data=([X_sent_val, X_pos_val,X_af3_val],np.array(y_val)))\n",
    "\n",
    "model.save(\"af3_sent_pos.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5402f9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: /data/ProcessedNYT/test_military.txt\n",
      "19/19 [==============================] - 8s 399ms/step - loss: 0.1419 - accuracy: 0.9620 - f1_m: 0.9639\n",
      "Test score: 0.14191938936710358\n",
      "Test accuracy: 0.9619834423065186\n",
      "Test f1 score: 0.9639169573783875\n",
      "Evaluating: /data/ProcessedNYT/test_law.txt\n",
      "20/20 [==============================] - 8s 400ms/step - loss: 0.2534 - accuracy: 0.9000 - f1_m: 0.9032\n",
      "Test score: 0.253448486328125\n",
      "Test accuracy: 0.8999999761581421\n",
      "Test f1 score: 0.9032188653945923\n",
      "Evaluating: /data/ProcessedNYT/test_finance.txt\n",
      "16/16 [==============================] - 6s 385ms/step - loss: 0.1652 - accuracy: 0.9412 - f1_m: 0.9411\n",
      "Test score: 0.1652163565158844\n",
      "Test accuracy: 0.9411764740943909\n",
      "Test f1 score: 0.9411458373069763\n",
      "Evaluating: /data/ProcessedNYT/test_education.txt\n",
      "10/10 [==============================] - 4s 414ms/step - loss: 0.2261 - accuracy: 0.9020 - f1_m: 0.9011\n",
      "Test score: 0.22611041367053986\n",
      "Test accuracy: 0.9020270109176636\n",
      "Test f1 score: 0.9010887145996094\n",
      "Evaluating: /data/ProcessedNYT/test_politics.txt\n",
      "43/43 [==============================] - 17s 398ms/step - loss: 0.1842 - accuracy: 0.9323 - f1_m: 0.9321\n",
      "Test score: 0.1842302531003952\n",
      "Test accuracy: 0.932314395904541\n",
      "Test f1 score: 0.9320682883262634\n",
      "Evaluating: /data/ProcessedNYT/test_medicine.txt\n",
      "10/10 [==============================] - 4s 387ms/step - loss: 0.3009 - accuracy: 0.8746 - f1_m: 0.8782\n",
      "Test score: 0.3008972108364105\n",
      "Test accuracy: 0.8745874762535095\n",
      "Test f1 score: 0.878188967704773\n"
     ]
    }
   ],
   "source": [
    "for idx,df in enumerate(list_of_dfs):\n",
    "    \n",
    "    print('Evaluating:',list_of_files[idx])\n",
    "    y_test, X_af3_test, X_sent_test, X_pos_test = process_test_df(df, af3=True, sent = True, pos=True)\n",
    "    \n",
    "    score, acc, f1 = model.evaluate([X_sent_test, X_pos_test, X_af3_test], y_test, batch_size=batch_size)\n",
    "    print('Test score:', score)\n",
    "    print('Test accuracy:', acc)\n",
    "    print('Test f1 score:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c8cd1e",
   "metadata": {},
   "source": [
    "## Combined model: argfeat6 + sent_sum + pos_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "773f1c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-09 23:20:40.075583: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-09 23:20:40.879439: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10413 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:84:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 4500)]       0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 100, 128)     384         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 4500, 128)    5760        ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)        (None, 100, 128)     768         ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " simple_rnn (SimpleRNN)         (None, 128)          32896       ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " simple_rnn_1 (SimpleRNN)       (None, 128)          32896       ['embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " simple_rnn_2 (SimpleRNN)       (None, 128)          32896       ['embedding_2[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 384)          0           ['simple_rnn[0][0]',             \n",
      "                                                                  'simple_rnn_1[0][0]',           \n",
      "                                                                  'simple_rnn_2[0][0]']           \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 2)            770         ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 106,370\n",
      "Trainable params: 106,370\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_sent = Input(shape=(X_sent.shape[1],))\n",
    "model_sent = Embedding(3, 128)(input_sent)\n",
    "model_sent = SimpleRNN(128, dropout=0.2)(model_sent)\n",
    "\n",
    "input_pos = Input(shape=(X_pos.shape[1],))\n",
    "model_pos = Embedding(len(le.classes_), 128)(input_pos)\n",
    "model_pos = SimpleRNN(128, dropout=0.2)(model_pos)\n",
    "\n",
    "input_af6 = Input(shape=(X_argfeat3.shape[1],))\n",
    "model_af6 = Embedding(6, 128)(input_af6)\n",
    "model_af6 = SimpleRNN(128, dropout=0.2)(model_af6)\n",
    "\n",
    "merged = Concatenate()([model_sent, model_pos, model_af6])\n",
    "dense_pred = (Dense(2, activation='sigmoid'))(merged)\n",
    "\n",
    "model = Model(inputs=[input_sent, input_pos, input_af6], outputs=dense_pred)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',f1_m])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9f15d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "70/70 [==============================] - 408s 6s/step - loss: 0.3828 - accuracy: 0.8401 - f1_m: 0.8371 - val_loss: 0.2620 - val_accuracy: 0.8977 - val_f1_m: 0.8953\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 415s 6s/step - loss: 0.2776 - accuracy: 0.8850 - f1_m: 0.8852 - val_loss: 0.2536 - val_accuracy: 0.9066 - val_f1_m: 0.9096\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 412s 6s/step - loss: 0.2584 - accuracy: 0.9061 - f1_m: 0.9045 - val_loss: 0.2303 - val_accuracy: 0.9031 - val_f1_m: 0.9069\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 410s 6s/step - loss: 0.2494 - accuracy: 0.9043 - f1_m: 0.9055 - val_loss: 0.2097 - val_accuracy: 0.9066 - val_f1_m: 0.9097\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 413s 6s/step - loss: 0.2739 - accuracy: 0.8854 - f1_m: 0.8856 - val_loss: 0.2300 - val_accuracy: 0.9048 - val_f1_m: 0.9049\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "model.fit([X_sent_train, X_pos_train,X_af6_train],np.array(y_train),\n",
    "          batch_size=batch_size,\n",
    "          epochs=5,\n",
    "          validation_data=([X_sent_val, X_pos_val,X_af6_val],np.array(y_val)))\n",
    "\n",
    "model.save(\"af6_sent_pos.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d40bf47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: /data/ProcessedNYT/test_military.txt\n",
      "19/19 [==============================] - 8s 426ms/step - loss: 0.1596 - accuracy: 0.9521 - f1_m: 0.9521\n",
      "Test score: 0.1596423089504242\n",
      "Test accuracy: 0.9520661234855652\n",
      "Test f1 score: 0.9521324634552002\n",
      "Evaluating: /data/ProcessedNYT/test_law.txt\n",
      "20/20 [==============================] - 8s 393ms/step - loss: 0.2833 - accuracy: 0.8672 - f1_m: 0.8749\n",
      "Test score: 0.2833259105682373\n",
      "Test accuracy: 0.8672131299972534\n",
      "Test f1 score: 0.8748556971549988\n",
      "Evaluating: /data/ProcessedNYT/test_finance.txt\n",
      "16/16 [==============================] - 6s 374ms/step - loss: 0.1879 - accuracy: 0.9196 - f1_m: 0.9228\n",
      "Test score: 0.18789760768413544\n",
      "Test accuracy: 0.9196078181266785\n",
      "Test f1 score: 0.9228276610374451\n",
      "Evaluating: /data/ProcessedNYT/test_education.txt\n",
      "10/10 [==============================] - 4s 379ms/step - loss: 0.2193 - accuracy: 0.9020 - f1_m: 0.9097\n",
      "Test score: 0.2193388044834137\n",
      "Test accuracy: 0.9020270109176636\n",
      "Test f1 score: 0.9097077250480652\n",
      "Evaluating: /data/ProcessedNYT/test_politics.txt\n",
      "43/43 [==============================] - 17s 390ms/step - loss: 0.1986 - accuracy: 0.9185 - f1_m: 0.9199\n",
      "Test score: 0.19857381284236908\n",
      "Test accuracy: 0.9184861779212952\n",
      "Test f1 score: 0.9198564887046814\n",
      "Evaluating: /data/ProcessedNYT/test_medicine.txt\n",
      "10/10 [==============================] - 4s 378ms/step - loss: 0.2836 - accuracy: 0.8779 - f1_m: 0.8826\n",
      "Test score: 0.28361776471138\n",
      "Test accuracy: 0.8778877854347229\n",
      "Test f1 score: 0.8826121091842651\n"
     ]
    }
   ],
   "source": [
    "for idx,df in enumerate(list_of_dfs):\n",
    "    \n",
    "    print('Evaluating:',list_of_files[idx])\n",
    "    y_test, X_af6_test, X_sent_test, X_pos_test = process_test_df(df, af6=True, sent = True, pos=True)\n",
    "    \n",
    "    score, acc, f1 = model.evaluate([X_sent_test, X_pos_test, X_af6_test], y_test, batch_size=batch_size)\n",
    "    print('Test score:', score)\n",
    "    print('Test accuracy:', acc)\n",
    "    print('Test f1 score:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a95bec1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bfb06b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
